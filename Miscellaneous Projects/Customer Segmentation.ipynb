{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 1344,
     "status": "ok",
     "timestamp": 1620812442737,
     "user": {
      "displayName": "Shailesh Rana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYEDPfmwGsvvPMYoptv9E5-yLMl_utG2HQtIuFug=s64",
      "userId": "06012920298662503859"
     },
     "user_tz": -330
    },
    "id": "v4MO3JnDcYKW"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 1146,
     "status": "ok",
     "timestamp": 1620812442738,
     "user": {
      "displayName": "Shailesh Rana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYEDPfmwGsvvPMYoptv9E5-yLMl_utG2HQtIuFug=s64",
      "userId": "06012920298662503859"
     },
     "user_tz": -330
    },
    "id": "Tq0umoLCdc49"
   },
   "outputs": [],
   "source": [
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 960,
     "status": "ok",
     "timestamp": 1620812442741,
     "user": {
      "displayName": "Shailesh Rana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYEDPfmwGsvvPMYoptv9E5-yLMl_utG2HQtIuFug=s64",
      "userId": "06012920298662503859"
     },
     "user_tz": -330
    },
    "id": "_48Fr8w4cYKk"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 2898,
     "status": "ok",
     "timestamp": 1620812444907,
     "user": {
      "displayName": "Shailesh Rana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYEDPfmwGsvvPMYoptv9E5-yLMl_utG2HQtIuFug=s64",
      "userId": "06012920298662503859"
     },
     "user_tz": -330
    },
    "id": "e-vnNu7-cYKl"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 2661,
     "status": "ok",
     "timestamp": 1620812444909,
     "user": {
      "displayName": "Shailesh Rana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYEDPfmwGsvvPMYoptv9E5-yLMl_utG2HQtIuFug=s64",
      "userId": "06012920298662503859"
     },
     "user_tz": -330
    },
    "id": "UiaW0NsvcYKn"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wOw8V4ZkcYKn"
   },
   "source": [
    "## Importing Training and Testing Databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "executionInfo": {
     "elapsed": 11127,
     "status": "ok",
     "timestamp": 1620812507314,
     "user": {
      "displayName": "Shailesh Rana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYEDPfmwGsvvPMYoptv9E5-yLMl_utG2HQtIuFug=s64",
      "userId": "06012920298662503859"
     },
     "user_tz": -330
    },
    "id": "-wQTfDNfdF5s",
    "outputId": "1533e316-a1a2-4ba2-a54a-78143f3cf86a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-c23ebf4d-9be5-446f-95d8-2dbf9e9eecc0\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-c23ebf4d-9be5-446f-95d8-2dbf9e9eecc0\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving x_test.csv to x_test.csv\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 1090,
     "status": "ok",
     "timestamp": 1620812465008,
     "user": {
      "displayName": "Shailesh Rana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYEDPfmwGsvvPMYoptv9E5-yLMl_utG2HQtIuFug=s64",
      "userId": "06012920298662503859"
     },
     "user_tz": -330
    },
    "id": "V85h7kBTcYKo"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(io.BytesIO(uploaded['Train.csv']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 1208,
     "status": "ok",
     "timestamp": 1620812493804,
     "user": {
      "displayName": "Shailesh Rana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYEDPfmwGsvvPMYoptv9E5-yLMl_utG2HQtIuFug=s64",
      "userId": "06012920298662503859"
     },
     "user_tz": -330
    },
    "id": "ZhdFgTU1cYKo"
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(io.BytesIO(uploaded['Test.csv']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1386,
     "status": "aborted",
     "timestamp": 1620811584297,
     "user": {
      "displayName": "Shailesh Rana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYEDPfmwGsvvPMYoptv9E5-yLMl_utG2HQtIuFug=s64",
      "userId": "06012920298662503859"
     },
     "user_tz": -330
    },
    "id": "l-dTpC8RcYKp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A6dVQjyccYKp"
   },
   "source": [
    "#### Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 1660,
     "status": "ok",
     "timestamp": 1620812527722,
     "user": {
      "displayName": "Shailesh Rana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYEDPfmwGsvvPMYoptv9E5-yLMl_utG2HQtIuFug=s64",
      "userId": "06012920298662503859"
     },
     "user_tz": -330
    },
    "id": "nm-OsKIMcYKq",
    "outputId": "9602bc03-0c4f-4002-dc9e-944fb7b0e8f0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ever_Married</th>\n",
       "      <th>Age</th>\n",
       "      <th>Graduated</th>\n",
       "      <th>Profession</th>\n",
       "      <th>Work_Experience</th>\n",
       "      <th>Spending_Score</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Var_1</th>\n",
       "      <th>Segmentation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>462809</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>22</td>\n",
       "      <td>No</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Cat_4</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>462643</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>38</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Average</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Cat_4</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>466315</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>67</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>461735</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>67</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>0.0</td>\n",
       "      <td>High</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>462669</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>40</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>High</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID  Gender Ever_Married  ...  Family_Size  Var_1 Segmentation\n",
       "0  462809    Male           No  ...          4.0  Cat_4            D\n",
       "1  462643  Female          Yes  ...          3.0  Cat_4            A\n",
       "2  466315  Female          Yes  ...          1.0  Cat_6            B\n",
       "3  461735    Male          Yes  ...          2.0  Cat_6            B\n",
       "4  462669  Female          Yes  ...          6.0  Cat_6            A\n",
       "\n",
       "[5 rows x 11 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y97ce5a4cYKs"
   },
   "source": [
    "Segmentation is the dependent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1420,
     "status": "ok",
     "timestamp": 1620812528727,
     "user": {
      "displayName": "Shailesh Rana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYEDPfmwGsvvPMYoptv9E5-yLMl_utG2HQtIuFug=s64",
      "userId": "06012920298662503859"
     },
     "user_tz": -330
    },
    "id": "KvL4dOKgcYKs",
    "outputId": "06d92cb2-e598-45db-bf84-39a4e4d27abf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                   0\n",
       "Gender               0\n",
       "Ever_Married       140\n",
       "Age                  0\n",
       "Graduated           78\n",
       "Profession         124\n",
       "Work_Experience    829\n",
       "Spending_Score       0\n",
       "Family_Size        335\n",
       "Var_1               76\n",
       "Segmentation         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum() #null values in all columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AMiiJFvhcYKt"
   },
   "source": [
    "##### Handling Nan Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ifm_lZ-BcYKu"
   },
   "source": [
    "##### Ever Married"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "executionInfo": {
     "elapsed": 1179,
     "status": "ok",
     "timestamp": 1620812529415,
     "user": {
      "displayName": "Shailesh Rana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYEDPfmwGsvvPMYoptv9E5-yLMl_utG2HQtIuFug=s64",
      "userId": "06012920298662503859"
     },
     "user_tz": -330
    },
    "id": "lDqwa7CUcYKu",
    "outputId": "e0306c08-8d15-4c4b-c65d-1fd87e1341bd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Graduated</th>\n",
       "      <th>Profession</th>\n",
       "      <th>Work_Experience</th>\n",
       "      <th>Spending_Score</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Var_1</th>\n",
       "      <th>Segmentation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ever_Married</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <td>3285</td>\n",
       "      <td>3285</td>\n",
       "      <td>3285</td>\n",
       "      <td>3254</td>\n",
       "      <td>3235</td>\n",
       "      <td>2960</td>\n",
       "      <td>3285</td>\n",
       "      <td>3101</td>\n",
       "      <td>3255</td>\n",
       "      <td>3285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>4643</td>\n",
       "      <td>4643</td>\n",
       "      <td>4643</td>\n",
       "      <td>4600</td>\n",
       "      <td>4573</td>\n",
       "      <td>4162</td>\n",
       "      <td>4643</td>\n",
       "      <td>4504</td>\n",
       "      <td>4598</td>\n",
       "      <td>4643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID  Gender   Age  ...  Family_Size  Var_1  Segmentation\n",
       "Ever_Married                      ...                                  \n",
       "No            3285    3285  3285  ...         3101   3255          3285\n",
       "Yes           4643    4643  4643  ...         4504   4598          4643\n",
       "\n",
       "[2 rows x 10 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby(['Ever_Married']).count() #shows 4643 Yes's and 3285 No's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 885,
     "status": "ok",
     "timestamp": 1620812529416,
     "user": {
      "displayName": "Shailesh Rana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYEDPfmwGsvvPMYoptv9E5-yLMl_utG2HQtIuFug=s64",
      "userId": "06012920298662503859"
     },
     "user_tz": -330
    },
    "id": "tW4qrQv0cYKv"
   },
   "outputs": [],
   "source": [
    "#Family size of 1 is more likely for people who never married\n",
    "train.loc[(train.Family_Size == 1) & (train.Ever_Married.isna()), \"Ever_Married\"] = 'No' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 1088,
     "status": "ok",
     "timestamp": 1620812529938,
     "user": {
      "displayName": "Shailesh Rana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYEDPfmwGsvvPMYoptv9E5-yLMl_utG2HQtIuFug=s64",
      "userId": "06012920298662503859"
     },
     "user_tz": -330
    },
    "id": "mGlP_91KcYKw"
   },
   "outputs": [],
   "source": [
    "#Age of 18 or less is more like to have never married\n",
    "train.loc[(train.Age <=18) & (train.Ever_Married.isna()), \"Ever_Married\"] = \"No\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1808,
     "status": "ok",
     "timestamp": 1620812530987,
     "user": {
      "displayName": "Shailesh Rana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYEDPfmwGsvvPMYoptv9E5-yLMl_utG2HQtIuFug=s64",
      "userId": "06012920298662503859"
     },
     "user_tz": -330
    },
    "id": "EcIFvrpVcYKw",
    "outputId": "83a4e31f-9481-4dcf-af79-27c2df140f5d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4204902576995602"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Ever_Married.isna().sum()/train.Ever_Married.count()*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3cbCxMQhcYKx"
   },
   "source": [
    "As such a low percentage of values are missing, we can replace them by the mode of the column, which is 'Yes'.\n",
    "So all remaining missing values will be replaced by 'yes'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 936,
     "status": "ok",
     "timestamp": 1620812530988,
     "user": {
      "displayName": "Shailesh Rana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYEDPfmwGsvvPMYoptv9E5-yLMl_utG2HQtIuFug=s64",
      "userId": "06012920298662503859"
     },
     "user_tz": -330
    },
    "id": "7vRZLNT8cYKy"
   },
   "outputs": [],
   "source": [
    "train.loc[train.Ever_Married.isna(), 'Ever_Married'] = 'Yes' #Filling nan values with Yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "executionInfo": {
     "elapsed": 1238,
     "status": "ok",
     "timestamp": 1620812531609,
     "user": {
      "displayName": "Shailesh Rana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYEDPfmwGsvvPMYoptv9E5-yLMl_utG2HQtIuFug=s64",
      "userId": "06012920298662503859"
     },
     "user_tz": -330
    },
    "id": "7conUnIPcYKy",
    "outputId": "927d8c71-7736-4668-ecd5-d88cb81f9dc3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Graduated</th>\n",
       "      <th>Profession</th>\n",
       "      <th>Work_Experience</th>\n",
       "      <th>Spending_Score</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Var_1</th>\n",
       "      <th>Segmentation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ever_Married</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <td>3312</td>\n",
       "      <td>3312</td>\n",
       "      <td>3312</td>\n",
       "      <td>3281</td>\n",
       "      <td>3261</td>\n",
       "      <td>2984</td>\n",
       "      <td>3312</td>\n",
       "      <td>3128</td>\n",
       "      <td>3281</td>\n",
       "      <td>3312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>4756</td>\n",
       "      <td>4756</td>\n",
       "      <td>4756</td>\n",
       "      <td>4709</td>\n",
       "      <td>4683</td>\n",
       "      <td>4255</td>\n",
       "      <td>4756</td>\n",
       "      <td>4605</td>\n",
       "      <td>4711</td>\n",
       "      <td>4756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID  Gender   Age  ...  Family_Size  Var_1  Segmentation\n",
       "Ever_Married                      ...                                  \n",
       "No            3312    3312  3312  ...         3128   3281          3312\n",
       "Yes           4756    4756  4756  ...         4605   4711          4756\n",
       "\n",
       "[2 rows x 10 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby(['Ever_Married']).count() #Yes's have increased from 4643"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 924,
     "status": "ok",
     "timestamp": 1620812531613,
     "user": {
      "displayName": "Shailesh Rana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYEDPfmwGsvvPMYoptv9E5-yLMl_utG2HQtIuFug=s64",
      "userId": "06012920298662503859"
     },
     "user_tz": -330
    },
    "id": "AA0D6S52cYKz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ME0WPeiucYKz"
   },
   "source": [
    "##### Graduated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "executionInfo": {
     "elapsed": 2041,
     "status": "ok",
     "timestamp": 1620812533897,
     "user": {
      "displayName": "Shailesh Rana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYEDPfmwGsvvPMYoptv9E5-yLMl_utG2HQtIuFug=s64",
      "userId": "06012920298662503859"
     },
     "user_tz": -330
    },
    "id": "Mm0x6wXOcYK0",
    "outputId": "084a888d-5fbd-4fc9-d99c-d1b943eecdab"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ever_Married</th>\n",
       "      <th>Age</th>\n",
       "      <th>Profession</th>\n",
       "      <th>Work_Experience</th>\n",
       "      <th>Spending_Score</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Var_1</th>\n",
       "      <th>Segmentation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Graduated</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <td>3022</td>\n",
       "      <td>3022</td>\n",
       "      <td>3022</td>\n",
       "      <td>3022</td>\n",
       "      <td>2958</td>\n",
       "      <td>2653</td>\n",
       "      <td>3022</td>\n",
       "      <td>2870</td>\n",
       "      <td>2986</td>\n",
       "      <td>3022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>4968</td>\n",
       "      <td>4968</td>\n",
       "      <td>4968</td>\n",
       "      <td>4968</td>\n",
       "      <td>4915</td>\n",
       "      <td>4520</td>\n",
       "      <td>4968</td>\n",
       "      <td>4793</td>\n",
       "      <td>4928</td>\n",
       "      <td>4968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID  Gender  Ever_Married  ...  Family_Size  Var_1  Segmentation\n",
       "Graduated                              ...                                  \n",
       "No         3022    3022          3022  ...         2870   2986          3022\n",
       "Yes        4968    4968          4968  ...         4793   4928          4968\n",
       "\n",
       "[2 rows x 10 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby(['Graduated']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "executionInfo": {
     "elapsed": 1684,
     "status": "ok",
     "timestamp": 1620812533899,
     "user": {
      "displayName": "Shailesh Rana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYEDPfmwGsvvPMYoptv9E5-yLMl_utG2HQtIuFug=s64",
      "userId": "06012920298662503859"
     },
     "user_tz": -330
    },
    "id": "sAW_u-RacYK1",
    "outputId": "bd8e29e8-f6e5-4d10-be9e-2986fd3d0f42"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, \"Age Distribution of Responders who haven't graduated\")"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(train.loc[train.Graduated == \"No\"].Age)\n",
    "plt.title(\"Age Distribution of Responders who haven't graduated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "executionInfo": {
     "elapsed": 2030,
     "status": "ok",
     "timestamp": 1620812534633,
     "user": {
      "displayName": "Shailesh Rana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYEDPfmwGsvvPMYoptv9E5-yLMl_utG2HQtIuFug=s64",
      "userId": "06012920298662503859"
     },
     "user_tz": -330
    },
    "id": "cnQKel-5cYK1",
    "outputId": "00215d5f-4fef-4b2e-adb6-16b5b3d98bfd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Age Distribution of All Responders')"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(train.Age)\n",
    "plt.title(\"Age Distribution of All Responders\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Una-ORBscYK2"
   },
   "source": [
    "Clearly the people who haven't graduated are more likely to be young, probably because they're still in college. We can assume that the younger people haven't graduated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 1424,
     "status": "ok",
     "timestamp": 1620812534635,
     "user": {
      "displayName": "Shailesh Rana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYEDPfmwGsvvPMYoptv9E5-yLMl_utG2HQtIuFug=s64",
      "userId": "06012920298662503859"
     },
     "user_tz": -330
    },
    "id": "j4NzOUkicYK3"
   },
   "outputs": [],
   "source": [
    "train.loc[(train.Age <=21) & (train.Graduated.isna()), \"Graduated\"] = \"No\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "executionInfo": {
     "elapsed": 1176,
     "status": "ok",
     "timestamp": 1620812534637,
     "user": {
      "displayName": "Shailesh Rana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYEDPfmwGsvvPMYoptv9E5-yLMl_utG2HQtIuFug=s64",
      "userId": "06012920298662503859"
     },
     "user_tz": -330
    },
    "id": "WzBIKUGocYK3",
    "outputId": "47eddf7b-6706-4691-f312-a08a508689af"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ever_Married</th>\n",
       "      <th>Age</th>\n",
       "      <th>Profession</th>\n",
       "      <th>Work_Experience</th>\n",
       "      <th>Spending_Score</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Var_1</th>\n",
       "      <th>Segmentation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Graduated</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <td>3030</td>\n",
       "      <td>3030</td>\n",
       "      <td>3030</td>\n",
       "      <td>3030</td>\n",
       "      <td>2966</td>\n",
       "      <td>2660</td>\n",
       "      <td>3030</td>\n",
       "      <td>2878</td>\n",
       "      <td>2994</td>\n",
       "      <td>3030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>4968</td>\n",
       "      <td>4968</td>\n",
       "      <td>4968</td>\n",
       "      <td>4968</td>\n",
       "      <td>4915</td>\n",
       "      <td>4520</td>\n",
       "      <td>4968</td>\n",
       "      <td>4793</td>\n",
       "      <td>4928</td>\n",
       "      <td>4968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID  Gender  Ever_Married  ...  Family_Size  Var_1  Segmentation\n",
       "Graduated                              ...                                  \n",
       "No         3030    3030          3030  ...         2878   2994          3030\n",
       "Yes        4968    4968          4968  ...         4793   4928          4968\n",
       "\n",
       "[2 rows x 10 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby(['Graduated']).count() #No's have changed from 3022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 1525,
     "status": "ok",
     "timestamp": 1620812535279,
     "user": {
      "displayName": "Shailesh Rana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYEDPfmwGsvvPMYoptv9E5-yLMl_utG2HQtIuFug=s64",
      "userId": "06012920298662503859"
     },
     "user_tz": -330
    },
    "id": "cRrKtmbZcYK3"
   },
   "outputs": [],
   "source": [
    "#changing all other values with the Mode of the column i.e. \"Yes\"\n",
    "train.loc[train.Graduated.isna(), \"Graduated\"] = \"Yes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "executionInfo": {
     "elapsed": 1246,
     "status": "ok",
     "timestamp": 1620812535283,
     "user": {
      "displayName": "Shailesh Rana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYEDPfmwGsvvPMYoptv9E5-yLMl_utG2HQtIuFug=s64",
      "userId": "06012920298662503859"
     },
     "user_tz": -330
    },
    "id": "WZ4r4JKVcYLF",
    "outputId": "218b1a2d-db09-4079-a4c2-152293b15f70"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ever_Married</th>\n",
       "      <th>Age</th>\n",
       "      <th>Profession</th>\n",
       "      <th>Work_Experience</th>\n",
       "      <th>Spending_Score</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Var_1</th>\n",
       "      <th>Segmentation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Graduated</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <td>3030</td>\n",
       "      <td>3030</td>\n",
       "      <td>3030</td>\n",
       "      <td>3030</td>\n",
       "      <td>2966</td>\n",
       "      <td>2660</td>\n",
       "      <td>3030</td>\n",
       "      <td>2878</td>\n",
       "      <td>2994</td>\n",
       "      <td>3030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>5038</td>\n",
       "      <td>5038</td>\n",
       "      <td>5038</td>\n",
       "      <td>5038</td>\n",
       "      <td>4978</td>\n",
       "      <td>4579</td>\n",
       "      <td>5038</td>\n",
       "      <td>4855</td>\n",
       "      <td>4998</td>\n",
       "      <td>5038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID  Gender  Ever_Married  ...  Family_Size  Var_1  Segmentation\n",
       "Graduated                              ...                                  \n",
       "No         3030    3030          3030  ...         2878   2994          3030\n",
       "Yes        5038    5038          5038  ...         4855   4998          5038\n",
       "\n",
       "[2 rows x 10 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby(['Graduated']).count() #Yes's have changed from 4968"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 1010,
     "status": "ok",
     "timestamp": 1620812535284,
     "user": {
      "displayName": "Shailesh Rana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYEDPfmwGsvvPMYoptv9E5-yLMl_utG2HQtIuFug=s64",
      "userId": "06012920298662503859"
     },
     "user_tz": -330
    },
    "id": "og-6I75CcYLG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rUkX38TncYLG"
   },
   "source": [
    "##### Profession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "executionInfo": {
     "elapsed": 925,
     "status": "ok",
     "timestamp": 1620812535800,
     "user": {
      "displayName": "Shailesh Rana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYEDPfmwGsvvPMYoptv9E5-yLMl_utG2HQtIuFug=s64",
      "userId": "06012920298662503859"
     },
     "user_tz": -330
    },
    "id": "IJv3yRTUcYLH",
    "outputId": "dd4bae62-e55d-4aa0-ae0e-bedfcc869a7e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ever_Married</th>\n",
       "      <th>Age</th>\n",
       "      <th>Graduated</th>\n",
       "      <th>Work_Experience</th>\n",
       "      <th>Spending_Score</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Var_1</th>\n",
       "      <th>Segmentation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Profession</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Artist</th>\n",
       "      <td>2516</td>\n",
       "      <td>2516</td>\n",
       "      <td>2516</td>\n",
       "      <td>2516</td>\n",
       "      <td>2516</td>\n",
       "      <td>2305</td>\n",
       "      <td>2516</td>\n",
       "      <td>2447</td>\n",
       "      <td>2491</td>\n",
       "      <td>2516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doctor</th>\n",
       "      <td>688</td>\n",
       "      <td>688</td>\n",
       "      <td>688</td>\n",
       "      <td>688</td>\n",
       "      <td>688</td>\n",
       "      <td>630</td>\n",
       "      <td>688</td>\n",
       "      <td>662</td>\n",
       "      <td>683</td>\n",
       "      <td>688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Engineer</th>\n",
       "      <td>699</td>\n",
       "      <td>699</td>\n",
       "      <td>699</td>\n",
       "      <td>699</td>\n",
       "      <td>699</td>\n",
       "      <td>628</td>\n",
       "      <td>699</td>\n",
       "      <td>673</td>\n",
       "      <td>694</td>\n",
       "      <td>699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entertainment</th>\n",
       "      <td>949</td>\n",
       "      <td>949</td>\n",
       "      <td>949</td>\n",
       "      <td>949</td>\n",
       "      <td>949</td>\n",
       "      <td>862</td>\n",
       "      <td>949</td>\n",
       "      <td>909</td>\n",
       "      <td>943</td>\n",
       "      <td>949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Executive</th>\n",
       "      <td>599</td>\n",
       "      <td>599</td>\n",
       "      <td>599</td>\n",
       "      <td>599</td>\n",
       "      <td>599</td>\n",
       "      <td>528</td>\n",
       "      <td>599</td>\n",
       "      <td>585</td>\n",
       "      <td>594</td>\n",
       "      <td>599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Healthcare</th>\n",
       "      <td>1332</td>\n",
       "      <td>1332</td>\n",
       "      <td>1332</td>\n",
       "      <td>1332</td>\n",
       "      <td>1332</td>\n",
       "      <td>1184</td>\n",
       "      <td>1332</td>\n",
       "      <td>1264</td>\n",
       "      <td>1317</td>\n",
       "      <td>1332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Homemaker</th>\n",
       "      <td>246</td>\n",
       "      <td>246</td>\n",
       "      <td>246</td>\n",
       "      <td>246</td>\n",
       "      <td>246</td>\n",
       "      <td>211</td>\n",
       "      <td>246</td>\n",
       "      <td>216</td>\n",
       "      <td>242</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lawyer</th>\n",
       "      <td>623</td>\n",
       "      <td>623</td>\n",
       "      <td>623</td>\n",
       "      <td>623</td>\n",
       "      <td>623</td>\n",
       "      <td>540</td>\n",
       "      <td>623</td>\n",
       "      <td>590</td>\n",
       "      <td>617</td>\n",
       "      <td>623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marketing</th>\n",
       "      <td>292</td>\n",
       "      <td>292</td>\n",
       "      <td>292</td>\n",
       "      <td>292</td>\n",
       "      <td>292</td>\n",
       "      <td>253</td>\n",
       "      <td>292</td>\n",
       "      <td>275</td>\n",
       "      <td>290</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID  Gender  Ever_Married  ...  Family_Size  Var_1  Segmentation\n",
       "Profession                                 ...                                  \n",
       "Artist         2516    2516          2516  ...         2447   2491          2516\n",
       "Doctor          688     688           688  ...          662    683           688\n",
       "Engineer        699     699           699  ...          673    694           699\n",
       "Entertainment   949     949           949  ...          909    943           949\n",
       "Executive       599     599           599  ...          585    594           599\n",
       "Healthcare     1332    1332          1332  ...         1264   1317          1332\n",
       "Homemaker       246     246           246  ...          216    242           246\n",
       "Lawyer          623     623           623  ...          590    617           623\n",
       "Marketing       292     292           292  ...          275    290           292\n",
       "\n",
       "[9 rows x 10 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby(['Profession']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "executionInfo": {
     "elapsed": 1720,
     "status": "ok",
     "timestamp": 1620812536925,
     "user": {
      "displayName": "Shailesh Rana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYEDPfmwGsvvPMYoptv9E5-yLMl_utG2HQtIuFug=s64",
      "userId": "06012920298662503859"
     },
     "user_tz": -330
    },
    "id": "XHSVT4SncYLH",
    "outputId": "617a27af-5881-4290-bdea-24f2153b3fb6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([850., 293., 295., 230.,   0., 288., 106., 385., 174., 345.]),\n",
       " array([0. , 0.8, 1.6, 2.4, 3.2, 4. , 4.8, 5.6, 6.4, 7.2, 8. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#most of the people who haven't graduated are in Healthcare\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.hist(train.loc[(train.Graduated == \"No\") & (train.Profession.isna() == False)].Profession)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "executionInfo": {
     "elapsed": 1306,
     "status": "ok",
     "timestamp": 1620812536928,
     "user": {
      "displayName": "Shailesh Rana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYEDPfmwGsvvPMYoptv9E5-yLMl_utG2HQtIuFug=s64",
      "userId": "06012920298662503859"
     },
     "user_tz": -330
    },
    "id": "fJeLPsf-cYLI",
    "outputId": "06e71386-be50-44b9-c3b6-da2a31e6bc28"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 314.,  393.,  604.,  482.,    0., 2223.,  140.,  400.,  304.,\n",
       "         118.]),\n",
       " array([0. , 0.8, 1.6, 2.4, 3.2, 4. , 4.8, 5.6, 6.4, 7.2, 8. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Peoplewho have Graduated are most commonly Artists\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.hist(train.loc[(train.Graduated == \"Yes\") & (train.Profession.isna() == False)].Profession)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "executionInfo": {
     "elapsed": 1403,
     "status": "ok",
     "timestamp": 1620812537401,
     "user": {
      "displayName": "Shailesh Rana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYEDPfmwGsvvPMYoptv9E5-yLMl_utG2HQtIuFug=s64",
      "userId": "06012920298662503859"
     },
     "user_tz": -330
    },
    "id": "trqzvsMKcYLJ"
   },
   "outputs": [],
   "source": [
    "#adding Healthcare as Profession for people who haven't graduated\n",
    "train.loc[(train.Graduated == \"No\") & (train.Profession.isna()), 'Profession'] = 'Healthcare'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "executionInfo": {
     "elapsed": 976,
     "status": "ok",
     "timestamp": 1620812537403,
     "user": {
      "displayName": "Shailesh Rana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYEDPfmwGsvvPMYoptv9E5-yLMl_utG2HQtIuFug=s64",
      "userId": "06012920298662503859"
     },
     "user_tz": -330
    },
    "id": "CS-3lLmTcYLK"
   },
   "outputs": [],
   "source": [
    "#adding Artist as Profession for people who have graduated\n",
    "train.loc[(train.Graduated == \"Yes\") & (train.Profession.isna()), 'Profession'] = 'Artist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "executionInfo": {
     "elapsed": 1535,
     "status": "ok",
     "timestamp": 1620812538352,
     "user": {
      "displayName": "Shailesh Rana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYEDPfmwGsvvPMYoptv9E5-yLMl_utG2HQtIuFug=s64",
      "userId": "06012920298662503859"
     },
     "user_tz": -330
    },
    "id": "dIXhqp3JcYLK",
    "outputId": "f8266288-6505-458d-94e8-52388769f15c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ever_Married</th>\n",
       "      <th>Age</th>\n",
       "      <th>Graduated</th>\n",
       "      <th>Work_Experience</th>\n",
       "      <th>Spending_Score</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Var_1</th>\n",
       "      <th>Segmentation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Profession</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Artist</th>\n",
       "      <td>2576</td>\n",
       "      <td>2576</td>\n",
       "      <td>2576</td>\n",
       "      <td>2576</td>\n",
       "      <td>2576</td>\n",
       "      <td>2355</td>\n",
       "      <td>2576</td>\n",
       "      <td>2503</td>\n",
       "      <td>2549</td>\n",
       "      <td>2576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doctor</th>\n",
       "      <td>688</td>\n",
       "      <td>688</td>\n",
       "      <td>688</td>\n",
       "      <td>688</td>\n",
       "      <td>688</td>\n",
       "      <td>630</td>\n",
       "      <td>688</td>\n",
       "      <td>662</td>\n",
       "      <td>683</td>\n",
       "      <td>688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Engineer</th>\n",
       "      <td>699</td>\n",
       "      <td>699</td>\n",
       "      <td>699</td>\n",
       "      <td>699</td>\n",
       "      <td>699</td>\n",
       "      <td>628</td>\n",
       "      <td>699</td>\n",
       "      <td>673</td>\n",
       "      <td>694</td>\n",
       "      <td>699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entertainment</th>\n",
       "      <td>949</td>\n",
       "      <td>949</td>\n",
       "      <td>949</td>\n",
       "      <td>949</td>\n",
       "      <td>949</td>\n",
       "      <td>862</td>\n",
       "      <td>949</td>\n",
       "      <td>909</td>\n",
       "      <td>943</td>\n",
       "      <td>949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Executive</th>\n",
       "      <td>599</td>\n",
       "      <td>599</td>\n",
       "      <td>599</td>\n",
       "      <td>599</td>\n",
       "      <td>599</td>\n",
       "      <td>528</td>\n",
       "      <td>599</td>\n",
       "      <td>585</td>\n",
       "      <td>594</td>\n",
       "      <td>599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Healthcare</th>\n",
       "      <td>1396</td>\n",
       "      <td>1396</td>\n",
       "      <td>1396</td>\n",
       "      <td>1396</td>\n",
       "      <td>1396</td>\n",
       "      <td>1232</td>\n",
       "      <td>1396</td>\n",
       "      <td>1320</td>\n",
       "      <td>1380</td>\n",
       "      <td>1396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Homemaker</th>\n",
       "      <td>246</td>\n",
       "      <td>246</td>\n",
       "      <td>246</td>\n",
       "      <td>246</td>\n",
       "      <td>246</td>\n",
       "      <td>211</td>\n",
       "      <td>246</td>\n",
       "      <td>216</td>\n",
       "      <td>242</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lawyer</th>\n",
       "      <td>623</td>\n",
       "      <td>623</td>\n",
       "      <td>623</td>\n",
       "      <td>623</td>\n",
       "      <td>623</td>\n",
       "      <td>540</td>\n",
       "      <td>623</td>\n",
       "      <td>590</td>\n",
       "      <td>617</td>\n",
       "      <td>623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marketing</th>\n",
       "      <td>292</td>\n",
       "      <td>292</td>\n",
       "      <td>292</td>\n",
       "      <td>292</td>\n",
       "      <td>292</td>\n",
       "      <td>253</td>\n",
       "      <td>292</td>\n",
       "      <td>275</td>\n",
       "      <td>290</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID  Gender  Ever_Married  ...  Family_Size  Var_1  Segmentation\n",
       "Profession                                 ...                                  \n",
       "Artist         2576    2576          2576  ...         2503   2549          2576\n",
       "Doctor          688     688           688  ...          662    683           688\n",
       "Engineer        699     699           699  ...          673    694           699\n",
       "Entertainment   949     949           949  ...          909    943           949\n",
       "Executive       599     599           599  ...          585    594           599\n",
       "Healthcare     1396    1396          1396  ...         1320   1380          1396\n",
       "Homemaker       246     246           246  ...          216    242           246\n",
       "Lawyer          623     623           623  ...          590    617           623\n",
       "Marketing       292     292           292  ...          275    290           292\n",
       "\n",
       "[9 rows x 10 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby(['Profession']).count() #Artist (2516) and Healthcare (1332) entries have increased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "executionInfo": {
     "elapsed": 1291,
     "status": "ok",
     "timestamp": 1620812538356,
     "user": {
      "displayName": "Shailesh Rana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYEDPfmwGsvvPMYoptv9E5-yLMl_utG2HQtIuFug=s64",
      "userId": "06012920298662503859"
     },
     "user_tz": -330
    },
    "id": "P7KBJzkIcYLL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bwpsiS7lcYLM"
   },
   "source": [
    "##### Work Experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 333
    },
    "executionInfo": {
     "elapsed": 1752,
     "status": "ok",
     "timestamp": 1620812539639,
     "user": {
      "displayName": "Shailesh Rana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYEDPfmwGsvvPMYoptv9E5-yLMl_utG2HQtIuFug=s64",
      "userId": "06012920298662503859"
     },
     "user_tz": -330
    },
    "id": "yJBPQjjecYLM",
    "outputId": "b065b4b8-5f22-49fc-bd1c-cf2336cd0cc5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4672.,  286.,  508.,  194.,  204.,  659.,  474.,  103.,   48.,\n",
       "          91.]),\n",
       " array([ 0. ,  1.4,  2.8,  4.2,  5.6,  7. ,  8.4,  9.8, 11.2, 12.6, 14. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(train.Work_Experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "executionInfo": {
     "elapsed": 1449,
     "status": "ok",
     "timestamp": 1620812539641,
     "user": {
      "displayName": "Shailesh Rana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYEDPfmwGsvvPMYoptv9E5-yLMl_utG2HQtIuFug=s64",
      "userId": "06012920298662503859"
     },
     "user_tz": -330
    },
    "id": "wE8om2u9cYLN"
   },
   "outputs": [],
   "source": [
    "#replacing nan values with 1.0\n",
    "train.loc[(train.Work_Experience.isna()), \"Work_Experience\"] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "executionInfo": {
     "elapsed": 1932,
     "status": "ok",
     "timestamp": 1620812540410,
     "user": {
      "displayName": "Shailesh Rana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYEDPfmwGsvvPMYoptv9E5-yLMl_utG2HQtIuFug=s64",
      "userId": "06012920298662503859"
     },
     "user_tz": -330
    },
    "id": "son2upowcYLN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pBkjX-4OcYLN"
   },
   "source": [
    "##### Family Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "executionInfo": {
     "elapsed": 1321,
     "status": "ok",
     "timestamp": 1620812540413,
     "user": {
      "displayName": "Shailesh Rana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYEDPfmwGsvvPMYoptv9E5-yLMl_utG2HQtIuFug=s64",
      "userId": "06012920298662503859"
     },
     "user_tz": -330
    },
    "id": "0b0AJj9jcYLO",
    "outputId": "f9a24ccd-145f-49de-ef35-286ef0db37bc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ever_Married</th>\n",
       "      <th>Age</th>\n",
       "      <th>Graduated</th>\n",
       "      <th>Profession</th>\n",
       "      <th>Work_Experience</th>\n",
       "      <th>Spending_Score</th>\n",
       "      <th>Var_1</th>\n",
       "      <th>Segmentation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Family_Size</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>1453</td>\n",
       "      <td>1453</td>\n",
       "      <td>1453</td>\n",
       "      <td>1453</td>\n",
       "      <td>1453</td>\n",
       "      <td>1453</td>\n",
       "      <td>1453</td>\n",
       "      <td>1453</td>\n",
       "      <td>1441</td>\n",
       "      <td>1453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>2390</td>\n",
       "      <td>2390</td>\n",
       "      <td>2390</td>\n",
       "      <td>2390</td>\n",
       "      <td>2390</td>\n",
       "      <td>2390</td>\n",
       "      <td>2390</td>\n",
       "      <td>2390</td>\n",
       "      <td>2371</td>\n",
       "      <td>2390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>1497</td>\n",
       "      <td>1497</td>\n",
       "      <td>1497</td>\n",
       "      <td>1497</td>\n",
       "      <td>1497</td>\n",
       "      <td>1497</td>\n",
       "      <td>1497</td>\n",
       "      <td>1497</td>\n",
       "      <td>1487</td>\n",
       "      <td>1497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>1379</td>\n",
       "      <td>1379</td>\n",
       "      <td>1379</td>\n",
       "      <td>1379</td>\n",
       "      <td>1379</td>\n",
       "      <td>1379</td>\n",
       "      <td>1379</td>\n",
       "      <td>1379</td>\n",
       "      <td>1367</td>\n",
       "      <td>1379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>612</td>\n",
       "      <td>612</td>\n",
       "      <td>612</td>\n",
       "      <td>612</td>\n",
       "      <td>612</td>\n",
       "      <td>612</td>\n",
       "      <td>612</td>\n",
       "      <td>612</td>\n",
       "      <td>603</td>\n",
       "      <td>612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.0</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.0</th>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID  Gender  Ever_Married  ...  Spending_Score  Var_1  Segmentation\n",
       "Family_Size                              ...                                     \n",
       "1.0          1453    1453          1453  ...            1453   1441          1453\n",
       "2.0          2390    2390          2390  ...            2390   2371          2390\n",
       "3.0          1497    1497          1497  ...            1497   1487          1497\n",
       "4.0          1379    1379          1379  ...            1379   1367          1379\n",
       "5.0           612     612           612  ...             612    603           612\n",
       "6.0           212     212           212  ...             212    212           212\n",
       "7.0            96      96            96  ...              96     96            96\n",
       "8.0            50      50            50  ...              50     50            50\n",
       "9.0            44      44            44  ...              44     44            44\n",
       "\n",
       "[9 rows x 10 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby([\"Family_Size\"]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1035,
     "status": "ok",
     "timestamp": 1620812540417,
     "user": {
      "displayName": "Shailesh Rana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYEDPfmwGsvvPMYoptv9E5-yLMl_utG2HQtIuFug=s64",
      "userId": "06012920298662503859"
     },
     "user_tz": -330
    },
    "id": "rs2AwRY1cYLO",
    "outputId": "04177b5f-074b-4ea7-c5c4-8d5280fdfd53"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Family_Size.mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "executionInfo": {
     "elapsed": 1665,
     "status": "ok",
     "timestamp": 1620812541397,
     "user": {
      "displayName": "Shailesh Rana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYEDPfmwGsvvPMYoptv9E5-yLMl_utG2HQtIuFug=s64",
      "userId": "06012920298662503859"
     },
     "user_tz": -330
    },
    "id": "35NLfNOScYLP",
    "outputId": "b562f0c5-0bc1-4f34-b4b4-2cd6876c551d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1453., 2390., 1497., 1379.,    0.,  612.,  212.,   96.,   50.,\n",
       "          44.]),\n",
       " array([1. , 1.8, 2.6, 3.4, 4.2, 5. , 5.8, 6.6, 7.4, 8.2, 9. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(train.Family_Size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "executionInfo": {
     "elapsed": 1378,
     "status": "ok",
     "timestamp": 1620812541399,
     "user": {
      "displayName": "Shailesh Rana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYEDPfmwGsvvPMYoptv9E5-yLMl_utG2HQtIuFug=s64",
      "userId": "06012920298662503859"
     },
     "user_tz": -330
    },
    "id": "T-3sded8cYLP"
   },
   "outputs": [],
   "source": [
    "#replacing nan values with the mode of the column, i.e. 2.0\n",
    "train.loc[train.Family_Size.isna(), 'Family_Size'] = 2.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "executionInfo": {
     "elapsed": 2003,
     "status": "ok",
     "timestamp": 1620812542338,
     "user": {
      "displayName": "Shailesh Rana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYEDPfmwGsvvPMYoptv9E5-yLMl_utG2HQtIuFug=s64",
      "userId": "06012920298662503859"
     },
     "user_tz": -330
    },
    "id": "71Q5tEDkcYLR",
    "outputId": "03ba7ca1-5956-4e4c-ef05-8c7f78b1042a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ever_Married</th>\n",
       "      <th>Age</th>\n",
       "      <th>Graduated</th>\n",
       "      <th>Profession</th>\n",
       "      <th>Work_Experience</th>\n",
       "      <th>Spending_Score</th>\n",
       "      <th>Var_1</th>\n",
       "      <th>Segmentation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Family_Size</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>1453</td>\n",
       "      <td>1453</td>\n",
       "      <td>1453</td>\n",
       "      <td>1453</td>\n",
       "      <td>1453</td>\n",
       "      <td>1453</td>\n",
       "      <td>1453</td>\n",
       "      <td>1453</td>\n",
       "      <td>1441</td>\n",
       "      <td>1453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>2725</td>\n",
       "      <td>2725</td>\n",
       "      <td>2725</td>\n",
       "      <td>2725</td>\n",
       "      <td>2725</td>\n",
       "      <td>2725</td>\n",
       "      <td>2725</td>\n",
       "      <td>2725</td>\n",
       "      <td>2692</td>\n",
       "      <td>2725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>1497</td>\n",
       "      <td>1497</td>\n",
       "      <td>1497</td>\n",
       "      <td>1497</td>\n",
       "      <td>1497</td>\n",
       "      <td>1497</td>\n",
       "      <td>1497</td>\n",
       "      <td>1497</td>\n",
       "      <td>1487</td>\n",
       "      <td>1497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>1379</td>\n",
       "      <td>1379</td>\n",
       "      <td>1379</td>\n",
       "      <td>1379</td>\n",
       "      <td>1379</td>\n",
       "      <td>1379</td>\n",
       "      <td>1379</td>\n",
       "      <td>1379</td>\n",
       "      <td>1367</td>\n",
       "      <td>1379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>612</td>\n",
       "      <td>612</td>\n",
       "      <td>612</td>\n",
       "      <td>612</td>\n",
       "      <td>612</td>\n",
       "      <td>612</td>\n",
       "      <td>612</td>\n",
       "      <td>612</td>\n",
       "      <td>603</td>\n",
       "      <td>612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.0</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.0</th>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID  Gender  Ever_Married  ...  Spending_Score  Var_1  Segmentation\n",
       "Family_Size                              ...                                     \n",
       "1.0          1453    1453          1453  ...            1453   1441          1453\n",
       "2.0          2725    2725          2725  ...            2725   2692          2725\n",
       "3.0          1497    1497          1497  ...            1497   1487          1497\n",
       "4.0          1379    1379          1379  ...            1379   1367          1379\n",
       "5.0           612     612           612  ...             612    603           612\n",
       "6.0           212     212           212  ...             212    212           212\n",
       "7.0            96      96            96  ...              96     96            96\n",
       "8.0            50      50            50  ...              50     50            50\n",
       "9.0            44      44            44  ...              44     44            44\n",
       "\n",
       "[9 rows x 10 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby(['Family_Size']).count() #the 2's have in creased from 2390"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "executionInfo": {
     "elapsed": 1620,
     "status": "ok",
     "timestamp": 1620812542341,
     "user": {
      "displayName": "Shailesh Rana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYEDPfmwGsvvPMYoptv9E5-yLMl_utG2HQtIuFug=s64",
      "userId": "06012920298662503859"
     },
     "user_tz": -330
    },
    "id": "Rvf7LMNZcYLU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jarh3dQccYLU"
   },
   "source": [
    "##### Var_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "executionInfo": {
     "elapsed": 1695,
     "status": "ok",
     "timestamp": 1620812543026,
     "user": {
      "displayName": "Shailesh Rana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYEDPfmwGsvvPMYoptv9E5-yLMl_utG2HQtIuFug=s64",
      "userId": "06012920298662503859"
     },
     "user_tz": -330
    },
    "id": "TQWMXXW1cYLV",
    "outputId": "d4707f64-5028-46f4-a556-bd0888a21e99"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ever_Married</th>\n",
       "      <th>Age</th>\n",
       "      <th>Graduated</th>\n",
       "      <th>Profession</th>\n",
       "      <th>Work_Experience</th>\n",
       "      <th>Spending_Score</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Segmentation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var_1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Cat_1</th>\n",
       "      <td>133</td>\n",
       "      <td>133</td>\n",
       "      <td>133</td>\n",
       "      <td>133</td>\n",
       "      <td>133</td>\n",
       "      <td>133</td>\n",
       "      <td>133</td>\n",
       "      <td>133</td>\n",
       "      <td>133</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cat_2</th>\n",
       "      <td>422</td>\n",
       "      <td>422</td>\n",
       "      <td>422</td>\n",
       "      <td>422</td>\n",
       "      <td>422</td>\n",
       "      <td>422</td>\n",
       "      <td>422</td>\n",
       "      <td>422</td>\n",
       "      <td>422</td>\n",
       "      <td>422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cat_3</th>\n",
       "      <td>822</td>\n",
       "      <td>822</td>\n",
       "      <td>822</td>\n",
       "      <td>822</td>\n",
       "      <td>822</td>\n",
       "      <td>822</td>\n",
       "      <td>822</td>\n",
       "      <td>822</td>\n",
       "      <td>822</td>\n",
       "      <td>822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cat_4</th>\n",
       "      <td>1089</td>\n",
       "      <td>1089</td>\n",
       "      <td>1089</td>\n",
       "      <td>1089</td>\n",
       "      <td>1089</td>\n",
       "      <td>1089</td>\n",
       "      <td>1089</td>\n",
       "      <td>1089</td>\n",
       "      <td>1089</td>\n",
       "      <td>1089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cat_5</th>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cat_6</th>\n",
       "      <td>5238</td>\n",
       "      <td>5238</td>\n",
       "      <td>5238</td>\n",
       "      <td>5238</td>\n",
       "      <td>5238</td>\n",
       "      <td>5238</td>\n",
       "      <td>5238</td>\n",
       "      <td>5238</td>\n",
       "      <td>5238</td>\n",
       "      <td>5238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cat_7</th>\n",
       "      <td>203</td>\n",
       "      <td>203</td>\n",
       "      <td>203</td>\n",
       "      <td>203</td>\n",
       "      <td>203</td>\n",
       "      <td>203</td>\n",
       "      <td>203</td>\n",
       "      <td>203</td>\n",
       "      <td>203</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID  Gender  Ever_Married  ...  Spending_Score  Family_Size  Segmentation\n",
       "Var_1                              ...                                           \n",
       "Cat_1   133     133           133  ...             133          133           133\n",
       "Cat_2   422     422           422  ...             422          422           422\n",
       "Cat_3   822     822           822  ...             822          822           822\n",
       "Cat_4  1089    1089          1089  ...            1089         1089          1089\n",
       "Cat_5    85      85            85  ...              85           85            85\n",
       "Cat_6  5238    5238          5238  ...            5238         5238          5238\n",
       "Cat_7   203     203           203  ...             203          203           203\n",
       "\n",
       "[7 rows x 10 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby(['Var_1']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "executionInfo": {
     "elapsed": 1376,
     "status": "ok",
     "timestamp": 1620812543027,
     "user": {
      "displayName": "Shailesh Rana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYEDPfmwGsvvPMYoptv9E5-yLMl_utG2HQtIuFug=s64",
      "userId": "06012920298662503859"
     },
     "user_tz": -330
    },
    "id": "PbtdiixNcYLV"
   },
   "outputs": [],
   "source": [
    "#replacing nan values with Cat_6\n",
    "train.loc[train.Var_1.isna(), 'Var_1'] = 'Cat_6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "executionInfo": {
     "elapsed": 2065,
     "status": "ok",
     "timestamp": 1620812544019,
     "user": {
      "displayName": "Shailesh Rana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYEDPfmwGsvvPMYoptv9E5-yLMl_utG2HQtIuFug=s64",
      "userId": "06012920298662503859"
     },
     "user_tz": -330
    },
    "id": "tySiAe1ZcYLW",
    "outputId": "37ac310f-0073-4d9e-c0ae-c657219e40ab"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ever_Married</th>\n",
       "      <th>Age</th>\n",
       "      <th>Graduated</th>\n",
       "      <th>Profession</th>\n",
       "      <th>Work_Experience</th>\n",
       "      <th>Spending_Score</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Segmentation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var_1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Cat_1</th>\n",
       "      <td>133</td>\n",
       "      <td>133</td>\n",
       "      <td>133</td>\n",
       "      <td>133</td>\n",
       "      <td>133</td>\n",
       "      <td>133</td>\n",
       "      <td>133</td>\n",
       "      <td>133</td>\n",
       "      <td>133</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cat_2</th>\n",
       "      <td>422</td>\n",
       "      <td>422</td>\n",
       "      <td>422</td>\n",
       "      <td>422</td>\n",
       "      <td>422</td>\n",
       "      <td>422</td>\n",
       "      <td>422</td>\n",
       "      <td>422</td>\n",
       "      <td>422</td>\n",
       "      <td>422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cat_3</th>\n",
       "      <td>822</td>\n",
       "      <td>822</td>\n",
       "      <td>822</td>\n",
       "      <td>822</td>\n",
       "      <td>822</td>\n",
       "      <td>822</td>\n",
       "      <td>822</td>\n",
       "      <td>822</td>\n",
       "      <td>822</td>\n",
       "      <td>822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cat_4</th>\n",
       "      <td>1089</td>\n",
       "      <td>1089</td>\n",
       "      <td>1089</td>\n",
       "      <td>1089</td>\n",
       "      <td>1089</td>\n",
       "      <td>1089</td>\n",
       "      <td>1089</td>\n",
       "      <td>1089</td>\n",
       "      <td>1089</td>\n",
       "      <td>1089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cat_5</th>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cat_6</th>\n",
       "      <td>5314</td>\n",
       "      <td>5314</td>\n",
       "      <td>5314</td>\n",
       "      <td>5314</td>\n",
       "      <td>5314</td>\n",
       "      <td>5314</td>\n",
       "      <td>5314</td>\n",
       "      <td>5314</td>\n",
       "      <td>5314</td>\n",
       "      <td>5314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cat_7</th>\n",
       "      <td>203</td>\n",
       "      <td>203</td>\n",
       "      <td>203</td>\n",
       "      <td>203</td>\n",
       "      <td>203</td>\n",
       "      <td>203</td>\n",
       "      <td>203</td>\n",
       "      <td>203</td>\n",
       "      <td>203</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID  Gender  Ever_Married  ...  Spending_Score  Family_Size  Segmentation\n",
       "Var_1                              ...                                           \n",
       "Cat_1   133     133           133  ...             133          133           133\n",
       "Cat_2   422     422           422  ...             422          422           422\n",
       "Cat_3   822     822           822  ...             822          822           822\n",
       "Cat_4  1089    1089          1089  ...            1089         1089          1089\n",
       "Cat_5    85      85            85  ...              85           85            85\n",
       "Cat_6  5314    5314          5314  ...            5314         5314          5314\n",
       "Cat_7   203     203           203  ...             203          203           203\n",
       "\n",
       "[7 rows x 10 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby(['Var_1']).count() #Cat_6 have increased from 5238"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "executionInfo": {
     "elapsed": 1783,
     "status": "ok",
     "timestamp": 1620812544023,
     "user": {
      "displayName": "Shailesh Rana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYEDPfmwGsvvPMYoptv9E5-yLMl_utG2HQtIuFug=s64",
      "userId": "06012920298662503859"
     },
     "user_tz": -330
    },
    "id": "XtcSrXlMcYLW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iOj2x_-1cYLX"
   },
   "source": [
    "###### No nan Values anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1098,
     "status": "ok",
     "timestamp": 1620812544024,
     "user": {
      "displayName": "Shailesh Rana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYEDPfmwGsvvPMYoptv9E5-yLMl_utG2HQtIuFug=s64",
      "userId": "06012920298662503859"
     },
     "user_tz": -330
    },
    "id": "LZPFGUyWcYLX",
    "outputId": "b958fdce-8567-4a63-bb83-ccd24fdff0f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                 0\n",
       "Gender             0\n",
       "Ever_Married       0\n",
       "Age                0\n",
       "Graduated          0\n",
       "Profession         0\n",
       "Work_Experience    0\n",
       "Spending_Score     0\n",
       "Family_Size        0\n",
       "Var_1              0\n",
       "Segmentation       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "executionInfo": {
     "elapsed": 1507,
     "status": "ok",
     "timestamp": 1620812544691,
     "user": {
      "displayName": "Shailesh Rana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYEDPfmwGsvvPMYoptv9E5-yLMl_utG2HQtIuFug=s64",
      "userId": "06012920298662503859"
     },
     "user_tz": -330
    },
    "id": "a2jMoQ-TcYLY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8cLVP6XZcYLY"
   },
   "source": [
    "#### Predictor Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "executionInfo": {
     "elapsed": 1446,
     "status": "ok",
     "timestamp": 1620812545174,
     "user": {
      "displayName": "Shailesh Rana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYEDPfmwGsvvPMYoptv9E5-yLMl_utG2HQtIuFug=s64",
      "userId": "06012920298662503859"
     },
     "user_tz": -330
    },
    "id": "Qg9x-Sw5cYLY",
    "outputId": "bfa1310b-7530-4b06-b7db-f6f0114b4fef"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ever_Married</th>\n",
       "      <th>Age</th>\n",
       "      <th>Graduated</th>\n",
       "      <th>Profession</th>\n",
       "      <th>Work_Experience</th>\n",
       "      <th>Spending_Score</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Var_1</th>\n",
       "      <th>Segmentation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>462809</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>22</td>\n",
       "      <td>No</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Cat_4</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>462643</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>38</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Average</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Cat_4</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>466315</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>67</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>461735</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>67</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>0.0</td>\n",
       "      <td>High</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>462669</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>40</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>1.0</td>\n",
       "      <td>High</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8063</th>\n",
       "      <td>464018</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>22</td>\n",
       "      <td>No</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Cat_1</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8064</th>\n",
       "      <td>464685</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>35</td>\n",
       "      <td>No</td>\n",
       "      <td>Executive</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Cat_4</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8065</th>\n",
       "      <td>465406</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>33</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8066</th>\n",
       "      <td>467299</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>27</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8067</th>\n",
       "      <td>461879</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>37</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Executive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Average</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Cat_4</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8068 rows  11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  Gender Ever_Married  ...  Family_Size  Var_1 Segmentation\n",
       "0     462809    Male           No  ...          4.0  Cat_4            D\n",
       "1     462643  Female          Yes  ...          3.0  Cat_4            A\n",
       "2     466315  Female          Yes  ...          1.0  Cat_6            B\n",
       "3     461735    Male          Yes  ...          2.0  Cat_6            B\n",
       "4     462669  Female          Yes  ...          6.0  Cat_6            A\n",
       "...      ...     ...          ...  ...          ...    ...          ...\n",
       "8063  464018    Male           No  ...          7.0  Cat_1            D\n",
       "8064  464685    Male           No  ...          4.0  Cat_4            D\n",
       "8065  465406  Female           No  ...          1.0  Cat_6            D\n",
       "8066  467299  Female           No  ...          4.0  Cat_6            B\n",
       "8067  461879    Male          Yes  ...          3.0  Cat_4            B\n",
       "\n",
       "[8068 rows x 11 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Y27ayR8cYLZ"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gNKD0PwFcYLZ"
   },
   "source": [
    "### Setting up Inputs to Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "executionInfo": {
     "elapsed": 1216,
     "status": "ok",
     "timestamp": 1620812545844,
     "user": {
      "displayName": "Shailesh Rana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYEDPfmwGsvvPMYoptv9E5-yLMl_utG2HQtIuFug=s64",
      "userId": "06012920298662503859"
     },
     "user_tz": -330
    },
    "id": "u8ig1U9jcYLZ"
   },
   "outputs": [],
   "source": [
    "#use dummy variables to convert categorical variables into numerical variables\n",
    "x_train = pd.get_dummies(train.iloc[:,1:-1]) #x_train are all independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1322,
     "status": "ok",
     "timestamp": 1620812546303,
     "user": {
      "displayName": "Shailesh Rana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYEDPfmwGsvvPMYoptv9E5-yLMl_utG2HQtIuFug=s64",
      "userId": "06012920298662503859"
     },
     "user_tz": -330
    },
    "id": "tJ80IW1jcYLa",
    "outputId": "7673532e-9579-46a5-857e-9f2c8300d209"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8068, 28)"
      ]
     },
     "execution_count": 51,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "executionInfo": {
     "elapsed": 1698,
     "status": "ok",
     "timestamp": 1620812547002,
     "user": {
      "displayName": "Shailesh Rana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYEDPfmwGsvvPMYoptv9E5-yLMl_utG2HQtIuFug=s64",
      "userId": "06012920298662503859"
     },
     "user_tz": -330
    },
    "id": "1QIXFePqcYLa"
   },
   "outputs": [],
   "source": [
    "y_train = pd.get_dummies(train.Segmentation) #y_train are dependent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "executionInfo": {
     "elapsed": 1283,
     "status": "ok",
     "timestamp": 1620812547005,
     "user": {
      "displayName": "Shailesh Rana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYEDPfmwGsvvPMYoptv9E5-yLMl_utG2HQtIuFug=s64",
      "userId": "06012920298662503859"
     },
     "user_tz": -330
    },
    "id": "2ueqH5aMcYLb"
   },
   "outputs": [],
   "source": [
    "y_train = y_train.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 906,
     "status": "ok",
     "timestamp": 1620812547006,
     "user": {
      "displayName": "Shailesh Rana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYEDPfmwGsvvPMYoptv9E5-yLMl_utG2HQtIuFug=s64",
      "userId": "06012920298662503859"
     },
     "user_tz": -330
    },
    "id": "jmJqsE-7cYLb",
    "outputId": "0c366a1a-41ac-466d-a1cc-7dbaef4781ca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8068, 4)"
      ]
     },
     "execution_count": 54,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "executionInfo": {
     "elapsed": 2131,
     "status": "ok",
     "timestamp": 1620812548593,
     "user": {
      "displayName": "Shailesh Rana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYEDPfmwGsvvPMYoptv9E5-yLMl_utG2HQtIuFug=s64",
      "userId": "06012920298662503859"
     },
     "user_tz": -330
    },
    "id": "W7chmBrVcYLb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rR42Y2ECcYLc"
   },
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "executionInfo": {
     "elapsed": 953,
     "status": "ok",
     "timestamp": 1620812551704,
     "user": {
      "displayName": "Shailesh Rana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYEDPfmwGsvvPMYoptv9E5-yLMl_utG2HQtIuFug=s64",
      "userId": "06012920298662503859"
     },
     "user_tz": -330
    },
    "id": "6jpVEwJYcYLc"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 366401,
     "status": "ok",
     "timestamp": 1620812968351,
     "user": {
      "displayName": "Shailesh Rana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYEDPfmwGsvvPMYoptv9E5-yLMl_utG2HQtIuFug=s64",
      "userId": "06012920298662503859"
     },
     "user_tz": -330
    },
    "id": "qAYOqfUjcYLc",
    "outputId": "e7a590d9-573a-4978-a618-e18b63cd21c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.4860 - val_loss: 0.4695\n",
      "Epoch 2/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4667 - val_loss: 0.4673\n",
      "Epoch 3/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4656 - val_loss: 0.4657\n",
      "Epoch 4/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4629 - val_loss: 0.4604\n",
      "Epoch 5/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4562 - val_loss: 0.4533\n",
      "Epoch 6/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4496 - val_loss: 0.4484\n",
      "Epoch 7/1000\n",
      "202/202 [==============================] - 0s 1ms/step - loss: 0.4441 - val_loss: 0.4465\n",
      "Epoch 8/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4433 - val_loss: 0.4448\n",
      "Epoch 9/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4430 - val_loss: 0.4440\n",
      "Epoch 10/1000\n",
      "202/202 [==============================] - 0s 1ms/step - loss: 0.4434 - val_loss: 0.4436\n",
      "Epoch 11/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4421 - val_loss: 0.4433\n",
      "Epoch 12/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4431 - val_loss: 0.4429\n",
      "Epoch 13/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4419 - val_loss: 0.4428\n",
      "Epoch 14/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4412 - val_loss: 0.4427\n",
      "Epoch 15/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4411 - val_loss: 0.4433\n",
      "Epoch 16/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4419 - val_loss: 0.4424\n",
      "Epoch 17/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4430 - val_loss: 0.4428\n",
      "Epoch 18/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4430 - val_loss: 0.4422\n",
      "Epoch 19/1000\n",
      "202/202 [==============================] - 0s 1ms/step - loss: 0.4444 - val_loss: 0.4422\n",
      "Epoch 20/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4409 - val_loss: 0.4421\n",
      "Epoch 21/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4395 - val_loss: 0.4422\n",
      "Epoch 22/1000\n",
      "202/202 [==============================] - 0s 1ms/step - loss: 0.4398 - val_loss: 0.4429\n",
      "Epoch 23/1000\n",
      "202/202 [==============================] - 0s 1ms/step - loss: 0.4420 - val_loss: 0.4420\n",
      "Epoch 24/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4405 - val_loss: 0.4422\n",
      "Epoch 25/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4385 - val_loss: 0.4420\n",
      "Epoch 26/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4400 - val_loss: 0.4420\n",
      "Epoch 27/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4409 - val_loss: 0.4433\n",
      "Epoch 28/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4400 - val_loss: 0.4421\n",
      "Epoch 29/1000\n",
      "202/202 [==============================] - 0s 1ms/step - loss: 0.4379 - val_loss: 0.4422\n",
      "Epoch 30/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4418 - val_loss: 0.4419\n",
      "Epoch 31/1000\n",
      "202/202 [==============================] - 0s 1ms/step - loss: 0.4420 - val_loss: 0.4419\n",
      "Epoch 32/1000\n",
      "202/202 [==============================] - 0s 1ms/step - loss: 0.4410 - val_loss: 0.4422\n",
      "Epoch 33/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4389 - val_loss: 0.4420\n",
      "Epoch 34/1000\n",
      "202/202 [==============================] - 0s 1ms/step - loss: 0.4398 - val_loss: 0.4417\n",
      "Epoch 35/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4411 - val_loss: 0.4418\n",
      "Epoch 36/1000\n",
      "202/202 [==============================] - 0s 1ms/step - loss: 0.4425 - val_loss: 0.4420\n",
      "Epoch 37/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4398 - val_loss: 0.4419\n",
      "Epoch 38/1000\n",
      "202/202 [==============================] - 0s 1ms/step - loss: 0.4425 - val_loss: 0.4420\n",
      "Epoch 39/1000\n",
      "202/202 [==============================] - 0s 1ms/step - loss: 0.4401 - val_loss: 0.4416\n",
      "Epoch 40/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4392 - val_loss: 0.4416\n",
      "Epoch 41/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4387 - val_loss: 0.4431\n",
      "Epoch 42/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4405 - val_loss: 0.4418\n",
      "Epoch 43/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4407 - val_loss: 0.4418\n",
      "Epoch 44/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4411 - val_loss: 0.4418\n",
      "Epoch 45/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4402 - val_loss: 0.4416\n",
      "Epoch 46/1000\n",
      "202/202 [==============================] - 0s 1ms/step - loss: 0.4400 - val_loss: 0.4416\n",
      "Epoch 47/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4402 - val_loss: 0.4416\n",
      "Epoch 48/1000\n",
      "202/202 [==============================] - 0s 1ms/step - loss: 0.4409 - val_loss: 0.4420\n",
      "Epoch 49/1000\n",
      "202/202 [==============================] - 0s 1ms/step - loss: 0.4397 - val_loss: 0.4415\n",
      "Epoch 50/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4390 - val_loss: 0.4418\n",
      "Epoch 51/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4379 - val_loss: 0.4421\n",
      "Epoch 52/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4381 - val_loss: 0.4417\n",
      "Epoch 53/1000\n",
      "202/202 [==============================] - 0s 1ms/step - loss: 0.4412 - val_loss: 0.4415\n",
      "Epoch 54/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4418 - val_loss: 0.4416\n",
      "Epoch 55/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4377 - val_loss: 0.4419\n",
      "Epoch 56/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4404 - val_loss: 0.4421\n",
      "Epoch 57/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4406 - val_loss: 0.4415\n",
      "Epoch 58/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4400 - val_loss: 0.4414\n",
      "Epoch 59/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4374 - val_loss: 0.4415\n",
      "Epoch 60/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4418 - val_loss: 0.4415\n",
      "Epoch 61/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4414 - val_loss: 0.4416\n",
      "Epoch 62/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4393 - val_loss: 0.4422\n",
      "Epoch 63/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4369 - val_loss: 0.4416\n",
      "Epoch 64/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4401 - val_loss: 0.4413\n",
      "Epoch 65/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4402 - val_loss: 0.4417\n",
      "Epoch 66/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4372 - val_loss: 0.4412\n",
      "Epoch 67/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4387 - val_loss: 0.4414\n",
      "Epoch 68/1000\n",
      "202/202 [==============================] - 0s 1ms/step - loss: 0.4426 - val_loss: 0.4419\n",
      "Epoch 69/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4393 - val_loss: 0.4413\n",
      "Epoch 70/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4379 - val_loss: 0.4416\n",
      "Epoch 71/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4377 - val_loss: 0.4412\n",
      "Epoch 72/1000\n",
      "202/202 [==============================] - 0s 1ms/step - loss: 0.4378 - val_loss: 0.4414\n",
      "Epoch 73/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4401 - val_loss: 0.4412\n",
      "Epoch 74/1000\n",
      "202/202 [==============================] - 0s 1ms/step - loss: 0.4400 - val_loss: 0.4414\n",
      "Epoch 75/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4384 - val_loss: 0.4411\n",
      "Epoch 76/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4407 - val_loss: 0.4411\n",
      "Epoch 77/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4395 - val_loss: 0.4410\n",
      "Epoch 78/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4380 - val_loss: 0.4418\n",
      "Epoch 79/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4410 - val_loss: 0.4410\n",
      "Epoch 80/1000\n",
      "202/202 [==============================] - 0s 1ms/step - loss: 0.4420 - val_loss: 0.4408\n",
      "Epoch 81/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4373 - val_loss: 0.4411\n",
      "Epoch 82/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4399 - val_loss: 0.4413\n",
      "Epoch 83/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4397 - val_loss: 0.4409\n",
      "Epoch 84/1000\n",
      "202/202 [==============================] - 0s 1ms/step - loss: 0.4391 - val_loss: 0.4412\n",
      "Epoch 85/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4375 - val_loss: 0.4409\n",
      "Epoch 86/1000\n",
      "202/202 [==============================] - 0s 1ms/step - loss: 0.4381 - val_loss: 0.4409\n",
      "Epoch 87/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4363 - val_loss: 0.4410\n",
      "Epoch 88/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4405 - val_loss: 0.4410\n",
      "Epoch 89/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4393 - val_loss: 0.4414\n",
      "Epoch 90/1000\n",
      "202/202 [==============================] - 0s 1ms/step - loss: 0.4397 - val_loss: 0.4408\n",
      "Epoch 91/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4390 - val_loss: 0.4410\n",
      "Epoch 92/1000\n",
      "202/202 [==============================] - 0s 1ms/step - loss: 0.4387 - val_loss: 0.4408\n",
      "Epoch 93/1000\n",
      "202/202 [==============================] - 0s 1ms/step - loss: 0.4389 - val_loss: 0.4408\n",
      "Epoch 94/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4418 - val_loss: 0.4413\n",
      "Epoch 95/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4374 - val_loss: 0.4406\n",
      "Epoch 96/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4396 - val_loss: 0.4409\n",
      "Epoch 97/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4379 - val_loss: 0.4415\n",
      "Epoch 98/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4367 - val_loss: 0.4409\n",
      "Epoch 99/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4412 - val_loss: 0.4407\n",
      "Epoch 100/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4387 - val_loss: 0.4409\n",
      "Epoch 101/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4385 - val_loss: 0.4409\n",
      "Epoch 102/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4375 - val_loss: 0.4407\n",
      "Epoch 103/1000\n",
      "202/202 [==============================] - 0s 1ms/step - loss: 0.4354 - val_loss: 0.4407\n",
      "Epoch 104/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4349 - val_loss: 0.4408\n",
      "Epoch 105/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4386 - val_loss: 0.4418\n",
      "Epoch 106/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4377 - val_loss: 0.4424\n",
      "Epoch 107/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4396 - val_loss: 0.4414\n",
      "Epoch 108/1000\n",
      "202/202 [==============================] - 0s 1ms/step - loss: 0.4357 - val_loss: 0.4411\n",
      "Epoch 109/1000\n",
      "202/202 [==============================] - 0s 1ms/step - loss: 0.4367 - val_loss: 0.4414\n",
      "Epoch 110/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4403 - val_loss: 0.4406\n",
      "Epoch 111/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4381 - val_loss: 0.4413\n",
      "Epoch 112/1000\n",
      "202/202 [==============================] - 0s 1ms/step - loss: 0.4386 - val_loss: 0.4407\n",
      "Epoch 113/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4374 - val_loss: 0.4412\n",
      "Epoch 114/1000\n",
      "202/202 [==============================] - 0s 1ms/step - loss: 0.4362 - val_loss: 0.4416\n",
      "Epoch 115/1000\n",
      "202/202 [==============================] - 0s 1ms/step - loss: 0.4376 - val_loss: 0.4410\n",
      "Epoch 116/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4353 - val_loss: 0.4407\n",
      "Epoch 117/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4370 - val_loss: 0.4424\n",
      "Epoch 118/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4412 - val_loss: 0.4408\n",
      "Epoch 119/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4370 - val_loss: 0.4407\n",
      "Epoch 120/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4368 - val_loss: 0.4408\n",
      "Epoch 121/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4365 - val_loss: 0.4417\n",
      "Epoch 122/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4416 - val_loss: 0.4412\n",
      "Epoch 123/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4369 - val_loss: 0.4406\n",
      "Epoch 124/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4346 - val_loss: 0.4406\n",
      "Epoch 125/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4374 - val_loss: 0.4408\n",
      "Epoch 126/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4385 - val_loss: 0.4412\n",
      "Epoch 127/1000\n",
      "202/202 [==============================] - 0s 1ms/step - loss: 0.4361 - val_loss: 0.4410\n",
      "Epoch 128/1000\n",
      "202/202 [==============================] - 0s 1ms/step - loss: 0.4367 - val_loss: 0.4406\n",
      "Epoch 129/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4386 - val_loss: 0.4410\n",
      "Epoch 130/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4381 - val_loss: 0.4414\n",
      "Epoch 131/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4369 - val_loss: 0.4415\n",
      "Epoch 132/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4376 - val_loss: 0.4407\n",
      "Epoch 133/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4354 - val_loss: 0.4410\n",
      "Epoch 134/1000\n",
      "202/202 [==============================] - 0s 1ms/step - loss: 0.4372 - val_loss: 0.4406\n",
      "Epoch 135/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4376 - val_loss: 0.4416\n",
      "Epoch 136/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4335 - val_loss: 0.4423\n",
      "Epoch 137/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4387 - val_loss: 0.4406\n",
      "Epoch 138/1000\n",
      "202/202 [==============================] - 0s 1ms/step - loss: 0.4389 - val_loss: 0.4410\n",
      "Epoch 139/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4401 - val_loss: 0.4405\n",
      "Epoch 140/1000\n",
      "202/202 [==============================] - 0s 1ms/step - loss: 0.4365 - val_loss: 0.4403\n",
      "Epoch 141/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4366 - val_loss: 0.4408\n",
      "Epoch 142/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4366 - val_loss: 0.4417\n",
      "Epoch 143/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4371 - val_loss: 0.4411\n",
      "Epoch 144/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4400 - val_loss: 0.4407\n",
      "Epoch 145/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4364 - val_loss: 0.4408\n",
      "Epoch 146/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4371 - val_loss: 0.4404\n",
      "Epoch 147/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4381 - val_loss: 0.4416\n",
      "Epoch 148/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4348 - val_loss: 0.4404\n",
      "Epoch 149/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4396 - val_loss: 0.4408\n",
      "Epoch 150/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4383 - val_loss: 0.4406\n",
      "Epoch 151/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4355 - val_loss: 0.4403\n",
      "Epoch 152/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4351 - val_loss: 0.4412\n",
      "Epoch 153/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4346 - val_loss: 0.4404\n",
      "Epoch 154/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4367 - val_loss: 0.4407\n",
      "Epoch 155/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4363 - val_loss: 0.4406\n",
      "Epoch 156/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4326 - val_loss: 0.4411\n",
      "Epoch 157/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4377 - val_loss: 0.4414\n",
      "Epoch 158/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4403 - val_loss: 0.4404\n",
      "Epoch 159/1000\n",
      "202/202 [==============================] - 0s 1ms/step - loss: 0.4383 - val_loss: 0.4412\n",
      "Epoch 160/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4376 - val_loss: 0.4402\n",
      "Epoch 161/1000\n",
      "202/202 [==============================] - 0s 1ms/step - loss: 0.4341 - val_loss: 0.4403\n",
      "Epoch 162/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4369 - val_loss: 0.4401\n",
      "Epoch 163/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4375 - val_loss: 0.4402\n",
      "Epoch 164/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4382 - val_loss: 0.4405\n",
      "Epoch 165/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4368 - val_loss: 0.4410\n",
      "Epoch 166/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4341 - val_loss: 0.4404\n",
      "Epoch 167/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4354 - val_loss: 0.4421\n",
      "Epoch 168/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4365 - val_loss: 0.4403\n",
      "Epoch 169/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4381 - val_loss: 0.4406\n",
      "Epoch 170/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4326 - val_loss: 0.4401\n",
      "Epoch 171/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4382 - val_loss: 0.4403\n",
      "Epoch 172/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4379 - val_loss: 0.4407\n",
      "Epoch 173/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4346 - val_loss: 0.4409\n",
      "Epoch 174/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4348 - val_loss: 0.4406\n",
      "Epoch 175/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4372 - val_loss: 0.4406\n",
      "Epoch 176/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4389 - val_loss: 0.4403\n",
      "Epoch 177/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4374 - val_loss: 0.4402\n",
      "Epoch 178/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4367 - val_loss: 0.4408\n",
      "Epoch 179/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4360 - val_loss: 0.4404\n",
      "Epoch 180/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4376 - val_loss: 0.4410\n",
      "Epoch 181/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4359 - val_loss: 0.4409\n",
      "Epoch 182/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4347 - val_loss: 0.4408\n",
      "Epoch 183/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4355 - val_loss: 0.4406\n",
      "Epoch 184/1000\n",
      "202/202 [==============================] - 0s 1ms/step - loss: 0.4359 - val_loss: 0.4408\n",
      "Epoch 185/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4380 - val_loss: 0.4408\n",
      "Epoch 186/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4360 - val_loss: 0.4423\n",
      "Epoch 187/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4389 - val_loss: 0.4409\n",
      "Epoch 188/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4347 - val_loss: 0.4411\n",
      "Epoch 189/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4365 - val_loss: 0.4405\n",
      "Epoch 190/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4350 - val_loss: 0.4400\n",
      "Epoch 191/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4369 - val_loss: 0.4410\n",
      "Epoch 192/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4390 - val_loss: 0.4412\n",
      "Epoch 193/1000\n",
      "202/202 [==============================] - 0s 1ms/step - loss: 0.4360 - val_loss: 0.4405\n",
      "Epoch 194/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4355 - val_loss: 0.4409\n",
      "Epoch 195/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4356 - val_loss: 0.4408\n",
      "Epoch 196/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4366 - val_loss: 0.4404\n",
      "Epoch 197/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4350 - val_loss: 0.4413\n",
      "Epoch 198/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4374 - val_loss: 0.4403\n",
      "Epoch 199/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4390 - val_loss: 0.4406\n",
      "Epoch 200/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4353 - val_loss: 0.4411\n",
      "Epoch 201/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4379 - val_loss: 0.4410\n",
      "Epoch 202/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4371 - val_loss: 0.4410\n",
      "Epoch 203/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4366 - val_loss: 0.4399\n",
      "Epoch 204/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4352 - val_loss: 0.4408\n",
      "Epoch 205/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4368 - val_loss: 0.4414\n",
      "Epoch 206/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4365 - val_loss: 0.4404\n",
      "Epoch 207/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4337 - val_loss: 0.4417\n",
      "Epoch 208/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4360 - val_loss: 0.4407\n",
      "Epoch 209/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4353 - val_loss: 0.4403\n",
      "Epoch 210/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4350 - val_loss: 0.4403\n",
      "Epoch 211/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4347 - val_loss: 0.4401\n",
      "Epoch 212/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4360 - val_loss: 0.4402\n",
      "Epoch 213/1000\n",
      "202/202 [==============================] - 0s 1ms/step - loss: 0.4364 - val_loss: 0.4403\n",
      "Epoch 214/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4336 - val_loss: 0.4402\n",
      "Epoch 215/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4364 - val_loss: 0.4403\n",
      "Epoch 216/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4369 - val_loss: 0.4399\n",
      "Epoch 217/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4347 - val_loss: 0.4403\n",
      "Epoch 218/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4384 - val_loss: 0.4401\n",
      "Epoch 219/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4381 - val_loss: 0.4405\n",
      "Epoch 220/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4359 - val_loss: 0.4402\n",
      "Epoch 221/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4353 - val_loss: 0.4409\n",
      "Epoch 222/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4349 - val_loss: 0.4402\n",
      "Epoch 223/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4322 - val_loss: 0.4407\n",
      "Epoch 224/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4326 - val_loss: 0.4402\n",
      "Epoch 225/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4359 - val_loss: 0.4400\n",
      "Epoch 226/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4371 - val_loss: 0.4411\n",
      "Epoch 227/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4345 - val_loss: 0.4400\n",
      "Epoch 228/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4355 - val_loss: 0.4405\n",
      "Epoch 229/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4365 - val_loss: 0.4401\n",
      "Epoch 230/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4365 - val_loss: 0.4404\n",
      "Epoch 231/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4375 - val_loss: 0.4405\n",
      "Epoch 232/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4363 - val_loss: 0.4401\n",
      "Epoch 233/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4342 - val_loss: 0.4400\n",
      "Epoch 234/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4332 - val_loss: 0.4401\n",
      "Epoch 235/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4331 - val_loss: 0.4406\n",
      "Epoch 236/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4360 - val_loss: 0.4399\n",
      "Epoch 237/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4348 - val_loss: 0.4406\n",
      "Epoch 238/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4343 - val_loss: 0.4406\n",
      "Epoch 239/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4363 - val_loss: 0.4410\n",
      "Epoch 240/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4369 - val_loss: 0.4402\n",
      "Epoch 241/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4371 - val_loss: 0.4400\n",
      "Epoch 242/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4358 - val_loss: 0.4407\n",
      "Epoch 243/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4351 - val_loss: 0.4401\n",
      "Epoch 244/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4365 - val_loss: 0.4411\n",
      "Epoch 245/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4370 - val_loss: 0.4404\n",
      "Epoch 246/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4353 - val_loss: 0.4397\n",
      "Epoch 247/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4384 - val_loss: 0.4412\n",
      "Epoch 248/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4349 - val_loss: 0.4400\n",
      "Epoch 249/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4341 - val_loss: 0.4399\n",
      "Epoch 250/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4355 - val_loss: 0.4401\n",
      "Epoch 251/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4374 - val_loss: 0.4406\n",
      "Epoch 252/1000\n",
      "202/202 [==============================] - 0s 1ms/step - loss: 0.4351 - val_loss: 0.4405\n",
      "Epoch 253/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4327 - val_loss: 0.4302\n",
      "Epoch 254/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4236 - val_loss: 0.4176\n",
      "Epoch 255/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.4043 - val_loss: 0.4044\n",
      "Epoch 256/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3986 - val_loss: 0.3999\n",
      "Epoch 257/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3969 - val_loss: 0.3982\n",
      "Epoch 258/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3962 - val_loss: 0.3972\n",
      "Epoch 259/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3956 - val_loss: 0.3966\n",
      "Epoch 260/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3927 - val_loss: 0.3950\n",
      "Epoch 261/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3918 - val_loss: 0.3944\n",
      "Epoch 262/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3896 - val_loss: 0.3935\n",
      "Epoch 263/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3894 - val_loss: 0.3933\n",
      "Epoch 264/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3879 - val_loss: 0.3915\n",
      "Epoch 265/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3890 - val_loss: 0.3916\n",
      "Epoch 266/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3871 - val_loss: 0.3904\n",
      "Epoch 267/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3886 - val_loss: 0.3900\n",
      "Epoch 268/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3877 - val_loss: 0.3899\n",
      "Epoch 269/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3859 - val_loss: 0.3912\n",
      "Epoch 270/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3884 - val_loss: 0.3903\n",
      "Epoch 271/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3848 - val_loss: 0.3876\n",
      "Epoch 272/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3849 - val_loss: 0.3885\n",
      "Epoch 273/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3883\n",
      "Epoch 274/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3837 - val_loss: 0.3866\n",
      "Epoch 275/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.3869\n",
      "Epoch 276/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3803 - val_loss: 0.3871\n",
      "Epoch 277/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3843 - val_loss: 0.3861\n",
      "Epoch 278/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3824 - val_loss: 0.3856\n",
      "Epoch 279/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3819 - val_loss: 0.3857\n",
      "Epoch 280/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3811 - val_loss: 0.3849\n",
      "Epoch 281/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3808 - val_loss: 0.3850\n",
      "Epoch 282/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3781 - val_loss: 0.3850\n",
      "Epoch 283/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3815 - val_loss: 0.3855\n",
      "Epoch 284/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3816 - val_loss: 0.3856\n",
      "Epoch 285/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3785 - val_loss: 0.3854\n",
      "Epoch 286/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3814 - val_loss: 0.3841\n",
      "Epoch 287/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3781 - val_loss: 0.3844\n",
      "Epoch 288/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3791 - val_loss: 0.3843\n",
      "Epoch 289/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3817 - val_loss: 0.3858\n",
      "Epoch 290/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3805 - val_loss: 0.3835\n",
      "Epoch 291/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3779 - val_loss: 0.3843\n",
      "Epoch 292/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3775 - val_loss: 0.3849\n",
      "Epoch 293/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3777 - val_loss: 0.3842\n",
      "Epoch 294/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3782 - val_loss: 0.3838\n",
      "Epoch 295/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3779 - val_loss: 0.3846\n",
      "Epoch 296/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.3838\n",
      "Epoch 297/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3767 - val_loss: 0.3835\n",
      "Epoch 298/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3755 - val_loss: 0.3831\n",
      "Epoch 299/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3778 - val_loss: 0.3839\n",
      "Epoch 300/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3791 - val_loss: 0.3846\n",
      "Epoch 301/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3789 - val_loss: 0.3824\n",
      "Epoch 302/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3773 - val_loss: 0.3836\n",
      "Epoch 303/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3786 - val_loss: 0.3843\n",
      "Epoch 304/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3761 - val_loss: 0.3827\n",
      "Epoch 305/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3789 - val_loss: 0.3826\n",
      "Epoch 306/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3789 - val_loss: 0.3830\n",
      "Epoch 307/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3782 - val_loss: 0.3832\n",
      "Epoch 308/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3791 - val_loss: 0.3844\n",
      "Epoch 309/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3783 - val_loss: 0.3830\n",
      "Epoch 310/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3790 - val_loss: 0.3831\n",
      "Epoch 311/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3788 - val_loss: 0.3823\n",
      "Epoch 312/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3773 - val_loss: 0.3831\n",
      "Epoch 313/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3792 - val_loss: 0.3825\n",
      "Epoch 314/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3789 - val_loss: 0.3827\n",
      "Epoch 315/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3790 - val_loss: 0.3824\n",
      "Epoch 316/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3781 - val_loss: 0.3832\n",
      "Epoch 317/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3822 - val_loss: 0.3822\n",
      "Epoch 318/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3782 - val_loss: 0.3819\n",
      "Epoch 319/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3777 - val_loss: 0.3823\n",
      "Epoch 320/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3754 - val_loss: 0.3840\n",
      "Epoch 321/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3795 - val_loss: 0.3814\n",
      "Epoch 322/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3779 - val_loss: 0.3815\n",
      "Epoch 323/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3776 - val_loss: 0.3832\n",
      "Epoch 324/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3776 - val_loss: 0.3838\n",
      "Epoch 325/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3759 - val_loss: 0.3819\n",
      "Epoch 326/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3759 - val_loss: 0.3824\n",
      "Epoch 327/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3766 - val_loss: 0.3821\n",
      "Epoch 328/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3791 - val_loss: 0.3817\n",
      "Epoch 329/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3760 - val_loss: 0.3834\n",
      "Epoch 330/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3754 - val_loss: 0.3828\n",
      "Epoch 331/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3754 - val_loss: 0.3817\n",
      "Epoch 332/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3763 - val_loss: 0.3817\n",
      "Epoch 333/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3767 - val_loss: 0.3818\n",
      "Epoch 334/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3787 - val_loss: 0.3816\n",
      "Epoch 335/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3743 - val_loss: 0.3819\n",
      "Epoch 336/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3768 - val_loss: 0.3810\n",
      "Epoch 337/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3744 - val_loss: 0.3813\n",
      "Epoch 338/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3767 - val_loss: 0.3824\n",
      "Epoch 339/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3775 - val_loss: 0.3814\n",
      "Epoch 340/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3766 - val_loss: 0.3817\n",
      "Epoch 341/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3776 - val_loss: 0.3816\n",
      "Epoch 342/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3755 - val_loss: 0.3820\n",
      "Epoch 343/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3738 - val_loss: 0.3832\n",
      "Epoch 344/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3762 - val_loss: 0.3839\n",
      "Epoch 345/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3761 - val_loss: 0.3831\n",
      "Epoch 346/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3755 - val_loss: 0.3809\n",
      "Epoch 347/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3771 - val_loss: 0.3823\n",
      "Epoch 348/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3726 - val_loss: 0.3814\n",
      "Epoch 349/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3799 - val_loss: 0.3816\n",
      "Epoch 350/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3744 - val_loss: 0.3819\n",
      "Epoch 351/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3765 - val_loss: 0.3814\n",
      "Epoch 352/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3763 - val_loss: 0.3847\n",
      "Epoch 353/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3772 - val_loss: 0.3824\n",
      "Epoch 354/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3759 - val_loss: 0.3814\n",
      "Epoch 355/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3749 - val_loss: 0.3810\n",
      "Epoch 356/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3760 - val_loss: 0.3810\n",
      "Epoch 357/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3764 - val_loss: 0.3822\n",
      "Epoch 358/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3749 - val_loss: 0.3817\n",
      "Epoch 359/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3744 - val_loss: 0.3820\n",
      "Epoch 360/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3783 - val_loss: 0.3838\n",
      "Epoch 361/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3756 - val_loss: 0.3820\n",
      "Epoch 362/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3746 - val_loss: 0.3825\n",
      "Epoch 363/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3762 - val_loss: 0.3817\n",
      "Epoch 364/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3765 - val_loss: 0.3827\n",
      "Epoch 365/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3747 - val_loss: 0.3818\n",
      "Epoch 366/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3757 - val_loss: 0.3811\n",
      "Epoch 367/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3751 - val_loss: 0.3831\n",
      "Epoch 368/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3752 - val_loss: 0.3821\n",
      "Epoch 369/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3745 - val_loss: 0.3835\n",
      "Epoch 370/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3767 - val_loss: 0.3823\n",
      "Epoch 371/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3758 - val_loss: 0.3814\n",
      "Epoch 372/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3751 - val_loss: 0.3828\n",
      "Epoch 373/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3752 - val_loss: 0.3819\n",
      "Epoch 374/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3756 - val_loss: 0.3829\n",
      "Epoch 375/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3752 - val_loss: 0.3817\n",
      "Epoch 376/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3747 - val_loss: 0.3817\n",
      "Epoch 377/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3744 - val_loss: 0.3823\n",
      "Epoch 378/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3755 - val_loss: 0.3815\n",
      "Epoch 379/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3759 - val_loss: 0.3830\n",
      "Epoch 380/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3730 - val_loss: 0.3822\n",
      "Epoch 381/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3761 - val_loss: 0.3824\n",
      "Epoch 382/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3759 - val_loss: 0.3820\n",
      "Epoch 383/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3743 - val_loss: 0.3827\n",
      "Epoch 384/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3755 - val_loss: 0.3831\n",
      "Epoch 385/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3756 - val_loss: 0.3828\n",
      "Epoch 386/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3772 - val_loss: 0.3818\n",
      "Epoch 387/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3763 - val_loss: 0.3823\n",
      "Epoch 388/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3724 - val_loss: 0.3827\n",
      "Epoch 389/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3738 - val_loss: 0.3826\n",
      "Epoch 390/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3727 - val_loss: 0.3831\n",
      "Epoch 391/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3754 - val_loss: 0.3838\n",
      "Epoch 392/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3751 - val_loss: 0.3821\n",
      "Epoch 393/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3791 - val_loss: 0.3821\n",
      "Epoch 394/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3730 - val_loss: 0.3817\n",
      "Epoch 395/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3752 - val_loss: 0.3821\n",
      "Epoch 396/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3742 - val_loss: 0.3821\n",
      "Epoch 397/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3744 - val_loss: 0.3817\n",
      "Epoch 398/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3771 - val_loss: 0.3815\n",
      "Epoch 399/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3726 - val_loss: 0.3827\n",
      "Epoch 400/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3733 - val_loss: 0.3821\n",
      "Epoch 401/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3738 - val_loss: 0.3823\n",
      "Epoch 402/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3742 - val_loss: 0.3836\n",
      "Epoch 403/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3754 - val_loss: 0.3834\n",
      "Epoch 404/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3775 - val_loss: 0.3835\n",
      "Epoch 405/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3733 - val_loss: 0.3828\n",
      "Epoch 406/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3719 - val_loss: 0.3819\n",
      "Epoch 407/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3735 - val_loss: 0.3827\n",
      "Epoch 408/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3776 - val_loss: 0.3819\n",
      "Epoch 409/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3750 - val_loss: 0.3819\n",
      "Epoch 410/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3760 - val_loss: 0.3828\n",
      "Epoch 411/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3766 - val_loss: 0.3819\n",
      "Epoch 412/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3754 - val_loss: 0.3820\n",
      "Epoch 413/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3751 - val_loss: 0.3831\n",
      "Epoch 414/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3777 - val_loss: 0.3844\n",
      "Epoch 415/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3764 - val_loss: 0.3824\n",
      "Epoch 416/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3762 - val_loss: 0.3825\n",
      "Epoch 417/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3753 - val_loss: 0.3822\n",
      "Epoch 418/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3733 - val_loss: 0.3822\n",
      "Epoch 419/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3769 - val_loss: 0.3828\n",
      "Epoch 420/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3750 - val_loss: 0.3825\n",
      "Epoch 421/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3728 - val_loss: 0.3824\n",
      "Epoch 422/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3746 - val_loss: 0.3825\n",
      "Epoch 423/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3744 - val_loss: 0.3829\n",
      "Epoch 424/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3746 - val_loss: 0.3815\n",
      "Epoch 425/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3759 - val_loss: 0.3828\n",
      "Epoch 426/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3750 - val_loss: 0.3822\n",
      "Epoch 427/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3744 - val_loss: 0.3819\n",
      "Epoch 428/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3775 - val_loss: 0.3821\n",
      "Epoch 429/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3722 - val_loss: 0.3824\n",
      "Epoch 430/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3734 - val_loss: 0.3820\n",
      "Epoch 431/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3768 - val_loss: 0.3822\n",
      "Epoch 432/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3750 - val_loss: 0.3840\n",
      "Epoch 433/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3748 - val_loss: 0.3833\n",
      "Epoch 434/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3764 - val_loss: 0.3818\n",
      "Epoch 435/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3747 - val_loss: 0.3834\n",
      "Epoch 436/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3749 - val_loss: 0.3833\n",
      "Epoch 437/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3771 - val_loss: 0.3827\n",
      "Epoch 438/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3732 - val_loss: 0.3831\n",
      "Epoch 439/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3736 - val_loss: 0.3833\n",
      "Epoch 440/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3737 - val_loss: 0.3822\n",
      "Epoch 441/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3727 - val_loss: 0.3825\n",
      "Epoch 442/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3741 - val_loss: 0.3844\n",
      "Epoch 443/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3744 - val_loss: 0.3822\n",
      "Epoch 444/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3739 - val_loss: 0.3830\n",
      "Epoch 445/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3747 - val_loss: 0.3823\n",
      "Epoch 446/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3714 - val_loss: 0.3827\n",
      "Epoch 447/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3746 - val_loss: 0.3824\n",
      "Epoch 448/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3742 - val_loss: 0.3852\n",
      "Epoch 449/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3763 - val_loss: 0.3826\n",
      "Epoch 450/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3737 - val_loss: 0.3815\n",
      "Epoch 451/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3763 - val_loss: 0.3824\n",
      "Epoch 452/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3739 - val_loss: 0.3866\n",
      "Epoch 453/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3736 - val_loss: 0.3827\n",
      "Epoch 454/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3758 - val_loss: 0.3820\n",
      "Epoch 455/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3747 - val_loss: 0.3815\n",
      "Epoch 456/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3760 - val_loss: 0.3829\n",
      "Epoch 457/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3721 - val_loss: 0.3824\n",
      "Epoch 458/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3735 - val_loss: 0.3815\n",
      "Epoch 459/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3717 - val_loss: 0.3821\n",
      "Epoch 460/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3740 - val_loss: 0.3823\n",
      "Epoch 461/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3763 - val_loss: 0.3825\n",
      "Epoch 462/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3750 - val_loss: 0.3837\n",
      "Epoch 463/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3738 - val_loss: 0.3829\n",
      "Epoch 464/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3741 - val_loss: 0.3830\n",
      "Epoch 465/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3778 - val_loss: 0.3821\n",
      "Epoch 466/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3759 - val_loss: 0.3819\n",
      "Epoch 467/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3732 - val_loss: 0.3828\n",
      "Epoch 468/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3732 - val_loss: 0.3842\n",
      "Epoch 469/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3740 - val_loss: 0.3819\n",
      "Epoch 470/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3744 - val_loss: 0.3823\n",
      "Epoch 471/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3730 - val_loss: 0.3819\n",
      "Epoch 472/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3748 - val_loss: 0.3829\n",
      "Epoch 473/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3752 - val_loss: 0.3831\n",
      "Epoch 474/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3725 - val_loss: 0.3835\n",
      "Epoch 475/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3683 - val_loss: 0.3825\n",
      "Epoch 476/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3737 - val_loss: 0.3831\n",
      "Epoch 477/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3730 - val_loss: 0.3824\n",
      "Epoch 478/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3743 - val_loss: 0.3821\n",
      "Epoch 479/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3721 - val_loss: 0.3826\n",
      "Epoch 480/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3710 - val_loss: 0.3833\n",
      "Epoch 481/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3756 - val_loss: 0.3826\n",
      "Epoch 482/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3740 - val_loss: 0.3824\n",
      "Epoch 483/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3744 - val_loss: 0.3845\n",
      "Epoch 484/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3751 - val_loss: 0.3824\n",
      "Epoch 485/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3745 - val_loss: 0.3830\n",
      "Epoch 486/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3721 - val_loss: 0.3831\n",
      "Epoch 487/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3735 - val_loss: 0.3826\n",
      "Epoch 488/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3743 - val_loss: 0.3829\n",
      "Epoch 489/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3698 - val_loss: 0.3822\n",
      "Epoch 490/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3724 - val_loss: 0.3821\n",
      "Epoch 491/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3730 - val_loss: 0.3833\n",
      "Epoch 492/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3733 - val_loss: 0.3821\n",
      "Epoch 493/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3740 - val_loss: 0.3825\n",
      "Epoch 494/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3734 - val_loss: 0.3828\n",
      "Epoch 495/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3744 - val_loss: 0.3825\n",
      "Epoch 496/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3724 - val_loss: 0.3819\n",
      "Epoch 497/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3752 - val_loss: 0.3821\n",
      "Epoch 498/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3742 - val_loss: 0.3837\n",
      "Epoch 499/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3751 - val_loss: 0.3814\n",
      "Epoch 500/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3728 - val_loss: 0.3832\n",
      "Epoch 501/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3747 - val_loss: 0.3827\n",
      "Epoch 502/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3731 - val_loss: 0.3817\n",
      "Epoch 503/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3716 - val_loss: 0.3825\n",
      "Epoch 504/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3745 - val_loss: 0.3819\n",
      "Epoch 505/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3730 - val_loss: 0.3820\n",
      "Epoch 506/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3739 - val_loss: 0.3814\n",
      "Epoch 507/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3704 - val_loss: 0.3821\n",
      "Epoch 508/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3724 - val_loss: 0.3823\n",
      "Epoch 509/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3716 - val_loss: 0.3825\n",
      "Epoch 510/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3740 - val_loss: 0.3818\n",
      "Epoch 511/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3734 - val_loss: 0.3823\n",
      "Epoch 512/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3728 - val_loss: 0.3817\n",
      "Epoch 513/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3698 - val_loss: 0.3819\n",
      "Epoch 514/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3730 - val_loss: 0.3826\n",
      "Epoch 515/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3738 - val_loss: 0.3830\n",
      "Epoch 516/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3719 - val_loss: 0.3819\n",
      "Epoch 517/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3737 - val_loss: 0.3832\n",
      "Epoch 518/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3745 - val_loss: 0.3822\n",
      "Epoch 519/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3732 - val_loss: 0.3819\n",
      "Epoch 520/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3738 - val_loss: 0.3816\n",
      "Epoch 521/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3702 - val_loss: 0.3825\n",
      "Epoch 522/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3742 - val_loss: 0.3826\n",
      "Epoch 523/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3711 - val_loss: 0.3818\n",
      "Epoch 524/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3726 - val_loss: 0.3828\n",
      "Epoch 525/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3727 - val_loss: 0.3820\n",
      "Epoch 526/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3734 - val_loss: 0.3822\n",
      "Epoch 527/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3713 - val_loss: 0.3834\n",
      "Epoch 528/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3723 - val_loss: 0.3822\n",
      "Epoch 529/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3721 - val_loss: 0.3845\n",
      "Epoch 530/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3715 - val_loss: 0.3839\n",
      "Epoch 531/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3761 - val_loss: 0.3822\n",
      "Epoch 532/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3759 - val_loss: 0.3824\n",
      "Epoch 533/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3723 - val_loss: 0.3815\n",
      "Epoch 534/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3726 - val_loss: 0.3817\n",
      "Epoch 535/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3714 - val_loss: 0.3825\n",
      "Epoch 536/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3734 - val_loss: 0.3829\n",
      "Epoch 537/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3735 - val_loss: 0.3850\n",
      "Epoch 538/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3735 - val_loss: 0.3822\n",
      "Epoch 539/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3697 - val_loss: 0.3818\n",
      "Epoch 540/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3681 - val_loss: 0.3822\n",
      "Epoch 541/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3730 - val_loss: 0.3819\n",
      "Epoch 542/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3742 - val_loss: 0.3822\n",
      "Epoch 543/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3748 - val_loss: 0.3825\n",
      "Epoch 544/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3706 - val_loss: 0.3819\n",
      "Epoch 545/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3734 - val_loss: 0.3818\n",
      "Epoch 546/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3721 - val_loss: 0.3832\n",
      "Epoch 547/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3727 - val_loss: 0.3816\n",
      "Epoch 548/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3720 - val_loss: 0.3823\n",
      "Epoch 549/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3735 - val_loss: 0.3820\n",
      "Epoch 550/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3719 - val_loss: 0.3817\n",
      "Epoch 551/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3713 - val_loss: 0.3826\n",
      "Epoch 552/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3725 - val_loss: 0.3823\n",
      "Epoch 553/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3757 - val_loss: 0.3816\n",
      "Epoch 554/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3721 - val_loss: 0.3819\n",
      "Epoch 555/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3735 - val_loss: 0.3833\n",
      "Epoch 556/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3739 - val_loss: 0.3820\n",
      "Epoch 557/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3753 - val_loss: 0.3821\n",
      "Epoch 558/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3704 - val_loss: 0.3840\n",
      "Epoch 559/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3743 - val_loss: 0.3829\n",
      "Epoch 560/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3761 - val_loss: 0.3817\n",
      "Epoch 561/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3736 - val_loss: 0.3826\n",
      "Epoch 562/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3709 - val_loss: 0.3813\n",
      "Epoch 563/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3724 - val_loss: 0.3827\n",
      "Epoch 564/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3720 - val_loss: 0.3821\n",
      "Epoch 565/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3718 - val_loss: 0.3826\n",
      "Epoch 566/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3752 - val_loss: 0.3821\n",
      "Epoch 567/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3740 - val_loss: 0.3818\n",
      "Epoch 568/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3738 - val_loss: 0.3823\n",
      "Epoch 569/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3736 - val_loss: 0.3818\n",
      "Epoch 570/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3734 - val_loss: 0.3817\n",
      "Epoch 571/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3720 - val_loss: 0.3821\n",
      "Epoch 572/1000\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.3754 - val_loss: 0.3814\n",
      "Epoch 573/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3714 - val_loss: 0.3826\n",
      "Epoch 574/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3731 - val_loss: 0.3832\n",
      "Epoch 575/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3717 - val_loss: 0.3814\n",
      "Epoch 576/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3751 - val_loss: 0.3821\n",
      "Epoch 577/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3706 - val_loss: 0.3819\n",
      "Epoch 578/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3719 - val_loss: 0.3821\n",
      "Epoch 579/1000\n",
      "202/202 [==============================] - 1s 2ms/step - loss: 0.3741 - val_loss: 0.3818\n",
      "Epoch 580/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3741 - val_loss: 0.3826\n",
      "Epoch 581/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3717 - val_loss: 0.3814\n",
      "Epoch 582/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3746 - val_loss: 0.3817\n",
      "Epoch 583/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3700 - val_loss: 0.3817\n",
      "Epoch 584/1000\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.3729 - val_loss: 0.3814\n",
      "Epoch 585/1000\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.3742 - val_loss: 0.3814\n",
      "Epoch 586/1000\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.3705 - val_loss: 0.3820\n",
      "Epoch 587/1000\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 0.3728 - val_loss: 0.3820\n",
      "Epoch 588/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3726 - val_loss: 0.3819\n",
      "Epoch 589/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3707 - val_loss: 0.3818\n",
      "Epoch 590/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3704 - val_loss: 0.3817\n",
      "Epoch 591/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3727 - val_loss: 0.3818\n",
      "Epoch 592/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3691 - val_loss: 0.3822\n",
      "Epoch 593/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3722 - val_loss: 0.3820\n",
      "Epoch 594/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3722 - val_loss: 0.3832\n",
      "Epoch 595/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3739 - val_loss: 0.3815\n",
      "Epoch 596/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3724 - val_loss: 0.3827\n",
      "Epoch 597/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3718 - val_loss: 0.3815\n",
      "Epoch 598/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3713 - val_loss: 0.3816\n",
      "Epoch 599/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3735 - val_loss: 0.3826\n",
      "Epoch 600/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3736 - val_loss: 0.3822\n",
      "Epoch 601/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3745 - val_loss: 0.3844\n",
      "Epoch 602/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3732 - val_loss: 0.3824\n",
      "Epoch 603/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3718 - val_loss: 0.3832\n",
      "Epoch 604/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3739 - val_loss: 0.3825\n",
      "Epoch 605/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3705 - val_loss: 0.3819\n",
      "Epoch 606/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3723 - val_loss: 0.3816\n",
      "Epoch 607/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3714 - val_loss: 0.3835\n",
      "Epoch 608/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3692 - val_loss: 0.3811\n",
      "Epoch 609/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3728 - val_loss: 0.3819\n",
      "Epoch 610/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3742 - val_loss: 0.3817\n",
      "Epoch 611/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3720 - val_loss: 0.3823\n",
      "Epoch 612/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3679 - val_loss: 0.3826\n",
      "Epoch 613/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3710 - val_loss: 0.3832\n",
      "Epoch 614/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3735 - val_loss: 0.3810\n",
      "Epoch 615/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3683 - val_loss: 0.3832\n",
      "Epoch 616/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3736 - val_loss: 0.3818\n",
      "Epoch 617/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3708 - val_loss: 0.3825\n",
      "Epoch 618/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3711 - val_loss: 0.3822\n",
      "Epoch 619/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3732 - val_loss: 0.3814\n",
      "Epoch 620/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3695 - val_loss: 0.3828\n",
      "Epoch 621/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3711 - val_loss: 0.3821\n",
      "Epoch 622/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3707 - val_loss: 0.3815\n",
      "Epoch 623/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3722 - val_loss: 0.3820\n",
      "Epoch 624/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3697 - val_loss: 0.3816\n",
      "Epoch 625/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3719 - val_loss: 0.3822\n",
      "Epoch 626/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3707 - val_loss: 0.3822\n",
      "Epoch 627/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3738 - val_loss: 0.3824\n",
      "Epoch 628/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3724 - val_loss: 0.3818\n",
      "Epoch 629/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3723 - val_loss: 0.3829\n",
      "Epoch 630/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3703 - val_loss: 0.3822\n",
      "Epoch 631/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3717 - val_loss: 0.3823\n",
      "Epoch 632/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3706 - val_loss: 0.3831\n",
      "Epoch 633/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3732 - val_loss: 0.3819\n",
      "Epoch 634/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3701 - val_loss: 0.3820\n",
      "Epoch 635/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3725 - val_loss: 0.3830\n",
      "Epoch 636/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3708 - val_loss: 0.3822\n",
      "Epoch 637/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3743 - val_loss: 0.3815\n",
      "Epoch 638/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3691 - val_loss: 0.3822\n",
      "Epoch 639/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3682 - val_loss: 0.3819\n",
      "Epoch 640/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3727 - val_loss: 0.3813\n",
      "Epoch 641/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3709 - val_loss: 0.3834\n",
      "Epoch 642/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3722 - val_loss: 0.3821\n",
      "Epoch 643/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3698 - val_loss: 0.3819\n",
      "Epoch 644/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3684 - val_loss: 0.3812\n",
      "Epoch 645/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3681 - val_loss: 0.3817\n",
      "Epoch 646/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3693 - val_loss: 0.3819\n",
      "Epoch 647/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3708 - val_loss: 0.3821\n",
      "Epoch 648/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3686 - val_loss: 0.3840\n",
      "Epoch 649/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3751 - val_loss: 0.3822\n",
      "Epoch 650/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3688 - val_loss: 0.3816\n",
      "Epoch 651/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3700 - val_loss: 0.3842\n",
      "Epoch 652/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3715 - val_loss: 0.3825\n",
      "Epoch 653/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3709 - val_loss: 0.3848\n",
      "Epoch 654/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3714 - val_loss: 0.3823\n",
      "Epoch 655/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3703 - val_loss: 0.3819\n",
      "Epoch 656/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3731 - val_loss: 0.3827\n",
      "Epoch 657/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3713 - val_loss: 0.3833\n",
      "Epoch 658/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3702 - val_loss: 0.3825\n",
      "Epoch 659/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3740 - val_loss: 0.3832\n",
      "Epoch 660/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3676 - val_loss: 0.3831\n",
      "Epoch 661/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3712 - val_loss: 0.3812\n",
      "Epoch 662/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3717 - val_loss: 0.3822\n",
      "Epoch 663/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3700 - val_loss: 0.3818\n",
      "Epoch 664/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3732 - val_loss: 0.3820\n",
      "Epoch 665/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3682 - val_loss: 0.3819\n",
      "Epoch 666/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3712 - val_loss: 0.3817\n",
      "Epoch 667/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3714 - val_loss: 0.3824\n",
      "Epoch 668/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3682 - val_loss: 0.3822\n",
      "Epoch 669/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3701 - val_loss: 0.3820\n",
      "Epoch 670/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3694 - val_loss: 0.3827\n",
      "Epoch 671/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3726 - val_loss: 0.3821\n",
      "Epoch 672/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3705 - val_loss: 0.3835\n",
      "Epoch 673/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3703 - val_loss: 0.3827\n",
      "Epoch 674/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3703 - val_loss: 0.3823\n",
      "Epoch 675/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3717 - val_loss: 0.3821\n",
      "Epoch 676/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3721 - val_loss: 0.3822\n",
      "Epoch 677/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3718 - val_loss: 0.3828\n",
      "Epoch 678/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3697 - val_loss: 0.3821\n",
      "Epoch 679/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3718 - val_loss: 0.3836\n",
      "Epoch 680/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3710 - val_loss: 0.3821\n",
      "Epoch 681/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3694 - val_loss: 0.3828\n",
      "Epoch 682/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3713 - val_loss: 0.3824\n",
      "Epoch 683/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3730 - val_loss: 0.3818\n",
      "Epoch 684/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3696 - val_loss: 0.3831\n",
      "Epoch 685/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3678 - val_loss: 0.3818\n",
      "Epoch 686/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3724 - val_loss: 0.3815\n",
      "Epoch 687/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3713 - val_loss: 0.3836\n",
      "Epoch 688/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3712 - val_loss: 0.3831\n",
      "Epoch 689/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3719 - val_loss: 0.3833\n",
      "Epoch 690/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3702 - val_loss: 0.3813\n",
      "Epoch 691/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3697 - val_loss: 0.3815\n",
      "Epoch 692/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3698 - val_loss: 0.3821\n",
      "Epoch 693/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3714 - val_loss: 0.3821\n",
      "Epoch 694/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3720 - val_loss: 0.3813\n",
      "Epoch 695/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3700 - val_loss: 0.3833\n",
      "Epoch 696/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3714 - val_loss: 0.3824\n",
      "Epoch 697/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3696 - val_loss: 0.3831\n",
      "Epoch 698/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3707 - val_loss: 0.3815\n",
      "Epoch 699/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3712 - val_loss: 0.3830\n",
      "Epoch 700/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3718 - val_loss: 0.3815\n",
      "Epoch 701/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3713 - val_loss: 0.3821\n",
      "Epoch 702/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3718 - val_loss: 0.3817\n",
      "Epoch 703/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3690 - val_loss: 0.3826\n",
      "Epoch 704/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3713 - val_loss: 0.3818\n",
      "Epoch 705/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3682 - val_loss: 0.3829\n",
      "Epoch 706/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3698 - val_loss: 0.3817\n",
      "Epoch 707/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3704 - val_loss: 0.3815\n",
      "Epoch 708/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3719 - val_loss: 0.3823\n",
      "Epoch 709/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3692 - val_loss: 0.3845\n",
      "Epoch 710/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3669 - val_loss: 0.3825\n",
      "Epoch 711/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3684 - val_loss: 0.3811\n",
      "Epoch 712/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3713 - val_loss: 0.3816\n",
      "Epoch 713/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3722 - val_loss: 0.3821\n",
      "Epoch 714/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3706 - val_loss: 0.3822\n",
      "Epoch 715/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3702 - val_loss: 0.3818\n",
      "Epoch 716/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3726 - val_loss: 0.3827\n",
      "Epoch 717/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3696 - val_loss: 0.3817\n",
      "Epoch 718/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3704 - val_loss: 0.3841\n",
      "Epoch 719/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3714 - val_loss: 0.3835\n",
      "Epoch 720/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3698 - val_loss: 0.3817\n",
      "Epoch 721/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3703 - val_loss: 0.3817\n",
      "Epoch 722/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3714 - val_loss: 0.3818\n",
      "Epoch 723/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3710 - val_loss: 0.3831\n",
      "Epoch 724/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3702 - val_loss: 0.3813\n",
      "Epoch 725/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3693 - val_loss: 0.3819\n",
      "Epoch 726/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3710 - val_loss: 0.3831\n",
      "Epoch 727/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3755 - val_loss: 0.3822\n",
      "Epoch 728/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3698 - val_loss: 0.3817\n",
      "Epoch 729/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3713 - val_loss: 0.3813\n",
      "Epoch 730/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3701 - val_loss: 0.3824\n",
      "Epoch 731/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3705 - val_loss: 0.3825\n",
      "Epoch 732/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3695 - val_loss: 0.3819\n",
      "Epoch 733/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3730 - val_loss: 0.3828\n",
      "Epoch 734/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3704 - val_loss: 0.3818\n",
      "Epoch 735/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3680 - val_loss: 0.3822\n",
      "Epoch 736/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3695 - val_loss: 0.3820\n",
      "Epoch 737/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3696 - val_loss: 0.3817\n",
      "Epoch 738/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3712 - val_loss: 0.3824\n",
      "Epoch 739/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3704 - val_loss: 0.3822\n",
      "Epoch 740/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3669 - val_loss: 0.3829\n",
      "Epoch 741/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3719 - val_loss: 0.3824\n",
      "Epoch 742/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3676 - val_loss: 0.3817\n",
      "Epoch 743/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3750 - val_loss: 0.3827\n",
      "Epoch 744/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3687 - val_loss: 0.3828\n",
      "Epoch 745/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3690 - val_loss: 0.3829\n",
      "Epoch 746/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3747 - val_loss: 0.3830\n",
      "Epoch 747/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3701 - val_loss: 0.3822\n",
      "Epoch 748/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3699 - val_loss: 0.3828\n",
      "Epoch 749/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3697 - val_loss: 0.3817\n",
      "Epoch 750/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3684 - val_loss: 0.3829\n",
      "Epoch 751/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3719 - val_loss: 0.3826\n",
      "Epoch 752/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3712 - val_loss: 0.3817\n",
      "Epoch 753/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3703 - val_loss: 0.3831\n",
      "Epoch 754/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3699 - val_loss: 0.3823\n",
      "Epoch 755/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3698 - val_loss: 0.3824\n",
      "Epoch 756/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3689 - val_loss: 0.3834\n",
      "Epoch 757/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3693 - val_loss: 0.3822\n",
      "Epoch 758/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3714 - val_loss: 0.3824\n",
      "Epoch 759/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3712 - val_loss: 0.3822\n",
      "Epoch 760/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3695 - val_loss: 0.3834\n",
      "Epoch 761/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3701 - val_loss: 0.3820\n",
      "Epoch 762/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3684 - val_loss: 0.3831\n",
      "Epoch 763/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3712 - val_loss: 0.3819\n",
      "Epoch 764/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3668 - val_loss: 0.3842\n",
      "Epoch 765/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3684 - val_loss: 0.3820\n",
      "Epoch 766/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3698 - val_loss: 0.3820\n",
      "Epoch 767/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3704 - val_loss: 0.3831\n",
      "Epoch 768/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3717 - val_loss: 0.3826\n",
      "Epoch 769/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3695 - val_loss: 0.3828\n",
      "Epoch 770/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3718 - val_loss: 0.3827\n",
      "Epoch 771/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3677 - val_loss: 0.3827\n",
      "Epoch 772/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3659 - val_loss: 0.3819\n",
      "Epoch 773/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3683 - val_loss: 0.3821\n",
      "Epoch 774/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3689 - val_loss: 0.3827\n",
      "Epoch 775/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3670 - val_loss: 0.3830\n",
      "Epoch 776/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3685 - val_loss: 0.3818\n",
      "Epoch 777/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3704 - val_loss: 0.3817\n",
      "Epoch 778/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3689 - val_loss: 0.3830\n",
      "Epoch 779/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3691 - val_loss: 0.3825\n",
      "Epoch 780/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3712 - val_loss: 0.3823\n",
      "Epoch 781/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3685 - val_loss: 0.3828\n",
      "Epoch 782/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3700 - val_loss: 0.3821\n",
      "Epoch 783/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3712 - val_loss: 0.3816\n",
      "Epoch 784/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3687 - val_loss: 0.3824\n",
      "Epoch 785/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3690 - val_loss: 0.3821\n",
      "Epoch 786/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3718 - val_loss: 0.3820\n",
      "Epoch 787/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3726 - val_loss: 0.3826\n",
      "Epoch 788/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3686 - val_loss: 0.3827\n",
      "Epoch 789/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3679 - val_loss: 0.3816\n",
      "Epoch 790/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3717 - val_loss: 0.3820\n",
      "Epoch 791/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3698 - val_loss: 0.3833\n",
      "Epoch 792/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3688 - val_loss: 0.3833\n",
      "Epoch 793/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3680 - val_loss: 0.3817\n",
      "Epoch 794/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3680 - val_loss: 0.3836\n",
      "Epoch 795/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3705 - val_loss: 0.3830\n",
      "Epoch 796/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3729 - val_loss: 0.3819\n",
      "Epoch 797/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3700 - val_loss: 0.3824\n",
      "Epoch 798/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3704 - val_loss: 0.3824\n",
      "Epoch 799/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3700 - val_loss: 0.3834\n",
      "Epoch 800/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3705 - val_loss: 0.3828\n",
      "Epoch 801/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3699 - val_loss: 0.3833\n",
      "Epoch 802/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3696 - val_loss: 0.3831\n",
      "Epoch 803/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3696 - val_loss: 0.3818\n",
      "Epoch 804/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3706 - val_loss: 0.3828\n",
      "Epoch 805/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3731 - val_loss: 0.3825\n",
      "Epoch 806/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3715 - val_loss: 0.3826\n",
      "Epoch 807/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3707 - val_loss: 0.3826\n",
      "Epoch 808/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3706 - val_loss: 0.3830\n",
      "Epoch 809/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3724 - val_loss: 0.3826\n",
      "Epoch 810/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3703 - val_loss: 0.3841\n",
      "Epoch 811/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3695 - val_loss: 0.3823\n",
      "Epoch 812/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3670 - val_loss: 0.3834\n",
      "Epoch 813/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3688 - val_loss: 0.3829\n",
      "Epoch 814/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3697 - val_loss: 0.3832\n",
      "Epoch 815/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3677 - val_loss: 0.3820\n",
      "Epoch 816/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3700 - val_loss: 0.3826\n",
      "Epoch 817/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3690 - val_loss: 0.3827\n",
      "Epoch 818/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3699 - val_loss: 0.3831\n",
      "Epoch 819/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3697 - val_loss: 0.3824\n",
      "Epoch 820/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3727 - val_loss: 0.3821\n",
      "Epoch 821/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3708 - val_loss: 0.3828\n",
      "Epoch 822/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3690 - val_loss: 0.3834\n",
      "Epoch 823/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3684 - val_loss: 0.3835\n",
      "Epoch 824/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3705 - val_loss: 0.3826\n",
      "Epoch 825/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3692 - val_loss: 0.3823\n",
      "Epoch 826/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3716 - val_loss: 0.3829\n",
      "Epoch 827/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3693 - val_loss: 0.3820\n",
      "Epoch 828/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3686 - val_loss: 0.3826\n",
      "Epoch 829/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3698 - val_loss: 0.3839\n",
      "Epoch 830/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3695 - val_loss: 0.3823\n",
      "Epoch 831/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3677 - val_loss: 0.3830\n",
      "Epoch 832/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3717 - val_loss: 0.3828\n",
      "Epoch 833/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3690 - val_loss: 0.3837\n",
      "Epoch 834/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3706 - val_loss: 0.3828\n",
      "Epoch 835/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3698 - val_loss: 0.3821\n",
      "Epoch 836/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3659 - val_loss: 0.3827\n",
      "Epoch 837/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3698 - val_loss: 0.3826\n",
      "Epoch 838/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3682 - val_loss: 0.3827\n",
      "Epoch 839/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3676 - val_loss: 0.3827\n",
      "Epoch 840/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3694 - val_loss: 0.3832\n",
      "Epoch 841/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3685 - val_loss: 0.3830\n",
      "Epoch 842/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3678 - val_loss: 0.3840\n",
      "Epoch 843/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3651 - val_loss: 0.3842\n",
      "Epoch 844/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3678 - val_loss: 0.3830\n",
      "Epoch 845/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3692 - val_loss: 0.3837\n",
      "Epoch 846/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3687 - val_loss: 0.3825\n",
      "Epoch 847/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3713 - val_loss: 0.3837\n",
      "Epoch 848/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3691 - val_loss: 0.3835\n",
      "Epoch 849/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3687 - val_loss: 0.3842\n",
      "Epoch 850/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3715 - val_loss: 0.3825\n",
      "Epoch 851/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3702 - val_loss: 0.3833\n",
      "Epoch 852/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3714 - val_loss: 0.3824\n",
      "Epoch 853/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3663 - val_loss: 0.3834\n",
      "Epoch 854/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3697 - val_loss: 0.3830\n",
      "Epoch 855/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3669 - val_loss: 0.3843\n",
      "Epoch 856/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3664 - val_loss: 0.3835\n",
      "Epoch 857/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3698 - val_loss: 0.3826\n",
      "Epoch 858/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3698 - val_loss: 0.3823\n",
      "Epoch 859/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3678 - val_loss: 0.3835\n",
      "Epoch 860/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3700 - val_loss: 0.3836\n",
      "Epoch 861/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3658 - val_loss: 0.3825\n",
      "Epoch 862/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3681 - val_loss: 0.3840\n",
      "Epoch 863/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3691 - val_loss: 0.3832\n",
      "Epoch 864/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3706 - val_loss: 0.3835\n",
      "Epoch 865/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3717 - val_loss: 0.3833\n",
      "Epoch 866/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3720 - val_loss: 0.3850\n",
      "Epoch 867/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3724 - val_loss: 0.3831\n",
      "Epoch 868/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3694 - val_loss: 0.3835\n",
      "Epoch 869/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3670 - val_loss: 0.3838\n",
      "Epoch 870/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3714 - val_loss: 0.3832\n",
      "Epoch 871/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3691 - val_loss: 0.3830\n",
      "Epoch 872/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3708 - val_loss: 0.3833\n",
      "Epoch 873/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3688 - val_loss: 0.3846\n",
      "Epoch 874/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3718 - val_loss: 0.3839\n",
      "Epoch 875/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3702 - val_loss: 0.3833\n",
      "Epoch 876/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3707 - val_loss: 0.3831\n",
      "Epoch 877/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3678 - val_loss: 0.3828\n",
      "Epoch 878/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3662 - val_loss: 0.3839\n",
      "Epoch 879/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3740 - val_loss: 0.3833\n",
      "Epoch 880/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3709 - val_loss: 0.3836\n",
      "Epoch 881/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3698 - val_loss: 0.3838\n",
      "Epoch 882/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3687 - val_loss: 0.3837\n",
      "Epoch 883/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3722 - val_loss: 0.3831\n",
      "Epoch 884/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3717 - val_loss: 0.3835\n",
      "Epoch 885/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3688 - val_loss: 0.3836\n",
      "Epoch 886/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3699 - val_loss: 0.3833\n",
      "Epoch 887/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3653 - val_loss: 0.3841\n",
      "Epoch 888/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3692 - val_loss: 0.3832\n",
      "Epoch 889/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3691 - val_loss: 0.3828\n",
      "Epoch 890/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3680 - val_loss: 0.3834\n",
      "Epoch 891/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3727 - val_loss: 0.3869\n",
      "Epoch 892/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3705 - val_loss: 0.3830\n",
      "Epoch 893/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3671 - val_loss: 0.3840\n",
      "Epoch 894/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3710 - val_loss: 0.3838\n",
      "Epoch 895/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3674 - val_loss: 0.3847\n",
      "Epoch 896/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3698 - val_loss: 0.3831\n",
      "Epoch 897/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3660 - val_loss: 0.3843\n",
      "Epoch 898/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3705 - val_loss: 0.3832\n",
      "Epoch 899/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3671 - val_loss: 0.3840\n",
      "Epoch 900/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3702 - val_loss: 0.3842\n",
      "Epoch 901/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3684 - val_loss: 0.3843\n",
      "Epoch 902/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3661 - val_loss: 0.3828\n",
      "Epoch 903/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3704 - val_loss: 0.3837\n",
      "Epoch 904/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3670 - val_loss: 0.3845\n",
      "Epoch 905/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3678 - val_loss: 0.3841\n",
      "Epoch 906/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3682 - val_loss: 0.3838\n",
      "Epoch 907/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3659 - val_loss: 0.3839\n",
      "Epoch 908/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3681 - val_loss: 0.3845\n",
      "Epoch 909/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3683 - val_loss: 0.3837\n",
      "Epoch 910/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3687 - val_loss: 0.3846\n",
      "Epoch 911/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3671 - val_loss: 0.3851\n",
      "Epoch 912/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3689 - val_loss: 0.3835\n",
      "Epoch 913/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3671 - val_loss: 0.3833\n",
      "Epoch 914/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3653 - val_loss: 0.3832\n",
      "Epoch 915/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3670 - val_loss: 0.3841\n",
      "Epoch 916/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3705 - val_loss: 0.3842\n",
      "Epoch 917/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3672 - val_loss: 0.3840\n",
      "Epoch 918/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3704 - val_loss: 0.3842\n",
      "Epoch 919/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3686 - val_loss: 0.3832\n",
      "Epoch 920/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3697 - val_loss: 0.3848\n",
      "Epoch 921/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3704 - val_loss: 0.3833\n",
      "Epoch 922/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3686 - val_loss: 0.3851\n",
      "Epoch 923/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3676 - val_loss: 0.3838\n",
      "Epoch 924/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3690 - val_loss: 0.3833\n",
      "Epoch 925/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3666 - val_loss: 0.3834\n",
      "Epoch 926/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3704 - val_loss: 0.3847\n",
      "Epoch 927/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3683 - val_loss: 0.3843\n",
      "Epoch 928/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3692 - val_loss: 0.3837\n",
      "Epoch 929/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3674 - val_loss: 0.3851\n",
      "Epoch 930/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3676 - val_loss: 0.3838\n",
      "Epoch 931/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3686 - val_loss: 0.3844\n",
      "Epoch 932/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3676 - val_loss: 0.3845\n",
      "Epoch 933/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3679 - val_loss: 0.3838\n",
      "Epoch 934/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3675 - val_loss: 0.3835\n",
      "Epoch 935/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3710 - val_loss: 0.3847\n",
      "Epoch 936/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3668 - val_loss: 0.3839\n",
      "Epoch 937/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3673 - val_loss: 0.3840\n",
      "Epoch 938/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3694 - val_loss: 0.3847\n",
      "Epoch 939/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3665 - val_loss: 0.3843\n",
      "Epoch 940/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3679 - val_loss: 0.3834\n",
      "Epoch 941/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3659 - val_loss: 0.3840\n",
      "Epoch 942/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3675 - val_loss: 0.3838\n",
      "Epoch 943/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3681 - val_loss: 0.3834\n",
      "Epoch 944/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3678 - val_loss: 0.3836\n",
      "Epoch 945/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3694 - val_loss: 0.3838\n",
      "Epoch 946/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3700 - val_loss: 0.3843\n",
      "Epoch 947/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3673 - val_loss: 0.3842\n",
      "Epoch 948/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3686 - val_loss: 0.3842\n",
      "Epoch 949/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3686 - val_loss: 0.3851\n",
      "Epoch 950/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3685 - val_loss: 0.3839\n",
      "Epoch 951/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3666 - val_loss: 0.3838\n",
      "Epoch 952/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3663 - val_loss: 0.3860\n",
      "Epoch 953/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3683 - val_loss: 0.3845\n",
      "Epoch 954/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3685 - val_loss: 0.3839\n",
      "Epoch 955/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3687 - val_loss: 0.3839\n",
      "Epoch 956/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3711 - val_loss: 0.3852\n",
      "Epoch 957/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3667 - val_loss: 0.3847\n",
      "Epoch 958/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3645 - val_loss: 0.3850\n",
      "Epoch 959/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3665 - val_loss: 0.3839\n",
      "Epoch 960/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3674 - val_loss: 0.3848\n",
      "Epoch 961/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3687 - val_loss: 0.3849\n",
      "Epoch 962/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3682 - val_loss: 0.3848\n",
      "Epoch 963/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3693 - val_loss: 0.3843\n",
      "Epoch 964/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3680 - val_loss: 0.3840\n",
      "Epoch 965/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3668 - val_loss: 0.3838\n",
      "Epoch 966/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3668 - val_loss: 0.3842\n",
      "Epoch 967/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3667 - val_loss: 0.3838\n",
      "Epoch 968/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3667 - val_loss: 0.3841\n",
      "Epoch 969/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3688 - val_loss: 0.3838\n",
      "Epoch 970/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3704 - val_loss: 0.3842\n",
      "Epoch 971/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3675 - val_loss: 0.3837\n",
      "Epoch 972/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3665 - val_loss: 0.3854\n",
      "Epoch 973/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3679 - val_loss: 0.3849\n",
      "Epoch 974/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3683 - val_loss: 0.3853\n",
      "Epoch 975/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3701 - val_loss: 0.3840\n",
      "Epoch 976/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3674 - val_loss: 0.3843\n",
      "Epoch 977/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3696 - val_loss: 0.3850\n",
      "Epoch 978/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3684 - val_loss: 0.3844\n",
      "Epoch 979/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3674 - val_loss: 0.3846\n",
      "Epoch 980/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3690 - val_loss: 0.3845\n",
      "Epoch 981/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3681 - val_loss: 0.3843\n",
      "Epoch 982/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3670 - val_loss: 0.3842\n",
      "Epoch 983/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3677 - val_loss: 0.3843\n",
      "Epoch 984/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3667 - val_loss: 0.3844\n",
      "Epoch 985/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3681 - val_loss: 0.3838\n",
      "Epoch 986/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3626 - val_loss: 0.3841\n",
      "Epoch 987/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3682 - val_loss: 0.3843\n",
      "Epoch 988/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3638 - val_loss: 0.3844\n",
      "Epoch 989/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3658 - val_loss: 0.3841\n",
      "Epoch 990/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3684 - val_loss: 0.3848\n",
      "Epoch 991/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3695 - val_loss: 0.3850\n",
      "Epoch 992/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3678 - val_loss: 0.3839\n",
      "Epoch 993/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3704 - val_loss: 0.3845\n",
      "Epoch 994/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3690 - val_loss: 0.3848\n",
      "Epoch 995/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3659 - val_loss: 0.3839\n",
      "Epoch 996/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3700 - val_loss: 0.3847\n",
      "Epoch 997/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3710 - val_loss: 0.3842\n",
      "Epoch 998/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3712 - val_loss: 0.3851\n",
      "Epoch 999/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3691 - val_loss: 0.3842\n",
      "Epoch 1000/1000\n",
      "202/202 [==============================] - 0s 2ms/step - loss: 0.3683 - val_loss: 0.3852\n"
     ]
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(18, kernel_initializer = 'random_normal', use_bias = True, bias_initializer=\"random_normal\", activation='relu',input_dim = 28))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(13, kernel_initializer = 'random_normal', use_bias = True, bias_initializer=\"random_normal\", activation='relu'))\n",
    "\n",
    "# Adding the third hidden layer\n",
    "classifier.add(Dense(9, kernel_initializer = 'random_normal', use_bias = True, bias_initializer=\"random_normal\", activation='relu'))\n",
    "\n",
    "#Adding the fourth hidden layer\n",
    "classifier.add(Dense(6, kernel_initializer = \"random_normal\", use_bias= True, bias_initializer= \"random_normal\", activation='relu'))\n",
    "\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(4, kernel_initializer = 'random_normal',use_bias = True, bias_initializer=\"random_normal\", activation='relu'))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(loss=root_mean_squared_error, optimizer='Adamax')\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "model_history=classifier.fit(x_train.values, y_train.values,validation_split=0.20, batch_size = 32, epochs = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NbVPSYezcYLd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "executionInfo": {
     "elapsed": 911,
     "status": "ok",
     "timestamp": 1620748968426,
     "user": {
      "displayName": "Shailesh Rana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYEDPfmwGsvvPMYoptv9E5-yLMl_utG2HQtIuFug=s64",
      "userId": "06012920298662503859"
     },
     "user_tz": -330
    },
    "id": "Shm6JgUncYLd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "du3MBYKeKxH9"
   },
   "source": [
    "Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "executionInfo": {
     "elapsed": 1390,
     "status": "ok",
     "timestamp": 1620813373304,
     "user": {
      "displayName": "Shailesh Rana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYEDPfmwGsvvPMYoptv9E5-yLMl_utG2HQtIuFug=s64",
      "userId": "06012920298662503859"
     },
     "user_tz": -330
    },
    "id": "shm3YNh-cYLe"
   },
   "outputs": [],
   "source": [
    "x_test = pd.read_csv(io.BytesIO(uploaded['x_test.csv']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "executionInfo": {
     "elapsed": 923,
     "status": "ok",
     "timestamp": 1620813373307,
     "user": {
      "displayName": "Shailesh Rana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYEDPfmwGsvvPMYoptv9E5-yLMl_utG2HQtIuFug=s64",
      "userId": "06012920298662503859"
     },
     "user_tz": -330
    },
    "id": "Xm8HWtKMK8XG"
   },
   "outputs": [],
   "source": [
    "x_test = x_test.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "executionInfo": {
     "elapsed": 1604,
     "status": "ok",
     "timestamp": 1620813441094,
     "user": {
      "displayName": "Shailesh Rana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYEDPfmwGsvvPMYoptv9E5-yLMl_utG2HQtIuFug=s64",
      "userId": "06012920298662503859"
     },
     "user_tz": -330
    },
    "id": "OfQsSZvHK93v"
   },
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame(classifier.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 1589,
     "status": "ok",
     "timestamp": 1620813441098,
     "user": {
      "displayName": "Shailesh Rana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYEDPfmwGsvvPMYoptv9E5-yLMl_utG2HQtIuFug=s64",
      "userId": "06012920298662503859"
     },
     "user_tz": -330
    },
    "id": "yAjZdnSO-oTR",
    "outputId": "07e62f39-7eb0-4739-d7e1-bf9d963be364"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.437051</td>\n",
       "      <td>0.350882</td>\n",
       "      <td>0.082679</td>\n",
       "      <td>0.122625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.431146</td>\n",
       "      <td>0.174896</td>\n",
       "      <td>0.193584</td>\n",
       "      <td>0.216529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.158453</td>\n",
       "      <td>0.043081</td>\n",
       "      <td>0.030802</td>\n",
       "      <td>0.698894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.402218</td>\n",
       "      <td>0.154786</td>\n",
       "      <td>0.322090</td>\n",
       "      <td>0.142152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.177844</td>\n",
       "      <td>0.112567</td>\n",
       "      <td>0.105131</td>\n",
       "      <td>0.576608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3\n",
       "0  0.437051  0.350882  0.082679  0.122625\n",
       "1  0.431146  0.174896  0.193584  0.216529\n",
       "2  0.158453  0.043081  0.030802  0.698894\n",
       "3  0.402218  0.154786  0.322090  0.142152\n",
       "4  0.177844  0.112567  0.105131  0.576608"
      ]
     },
     "execution_count": 91,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "executionInfo": {
     "elapsed": 1347,
     "status": "ok",
     "timestamp": 1620813446459,
     "user": {
      "displayName": "Shailesh Rana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYEDPfmwGsvvPMYoptv9E5-yLMl_utG2HQtIuFug=s64",
      "userId": "06012920298662503859"
     },
     "user_tz": -330
    },
    "id": "Cd2KWZ2x_CUO"
   },
   "outputs": [],
   "source": [
    "predictions.columns = ['A', 'B', 'C', 'D']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "executionInfo": {
     "elapsed": 816,
     "status": "ok",
     "timestamp": 1620813448457,
     "user": {
      "displayName": "Shailesh Rana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYEDPfmwGsvvPMYoptv9E5-yLMl_utG2HQtIuFug=s64",
      "userId": "06012920298662503859"
     },
     "user_tz": -330
    },
    "id": "dYI2Xk3a_JI7"
   },
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame(predictions.idxmax(axis = 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "executionInfo": {
     "elapsed": 1195,
     "status": "ok",
     "timestamp": 1620813451067,
     "user": {
      "displayName": "Shailesh Rana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYEDPfmwGsvvPMYoptv9E5-yLMl_utG2HQtIuFug=s64",
      "userId": "06012920298662503859"
     },
     "user_tz": -330
    },
    "id": "bVYM5f7v_Sv1"
   },
   "outputs": [],
   "source": [
    "predictions['ID'] = test.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 826,
     "status": "ok",
     "timestamp": 1620813451593,
     "user": {
      "displayName": "Shailesh Rana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYEDPfmwGsvvPMYoptv9E5-yLMl_utG2HQtIuFug=s64",
      "userId": "06012920298662503859"
     },
     "user_tz": -330
    },
    "id": "vnhCqKD5_jh-",
    "outputId": "ad8e4fdb-8ade-4aab-80cc-e2ef1f4c4d42"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>458989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>458994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D</td>\n",
       "      <td>458996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>459000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D</td>\n",
       "      <td>459001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      ID\n",
       "0  A  458989\n",
       "1  A  458994\n",
       "2  D  458996\n",
       "3  A  459000\n",
       "4  D  459001"
      ]
     },
     "execution_count": 95,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 109999,
     "status": "ok",
     "timestamp": 1620813707459,
     "user": {
      "displayName": "Shailesh Rana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYEDPfmwGsvvPMYoptv9E5-yLMl_utG2HQtIuFug=s64",
      "userId": "06012920298662503859"
     },
     "user_tz": -330
    },
    "id": "UL82gYn-BMC4",
    "outputId": "1ec19821-279d-4a92-a3be-786180392f7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /gdrive\n"
     ]
    }
   ],
   "source": [
    "# Import Drive API and authenticate.\n",
    "from google.colab import drive\n",
    "\n",
    "# Mount your Drive to the Colab VM.\n",
    "drive.mount('/gdrive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "executionInfo": {
     "elapsed": 1226,
     "status": "ok",
     "timestamp": 1620814056312,
     "user": {
      "displayName": "Shailesh Rana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjYEDPfmwGsvvPMYoptv9E5-yLMl_utG2HQtIuFug=s64",
      "userId": "06012920298662503859"
     },
     "user_tz": -330
    },
    "id": "0q0uHTp2AL4B"
   },
   "outputs": [],
   "source": [
    "predictions.to_csv('Predictions.csv', index = False)\n",
    "!cp Predictions.csv \"/gdrive/My Drive/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vRz06GfZA5xz"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Customer Segmentation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
