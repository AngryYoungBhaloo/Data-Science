{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv(r'C:\\Users\\Yogen\\Documents\\Data Analysis and Machine Learning\\Ishan Competition- Job Acceptance\\Training-Modified.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SLNO</th>\n",
       "      <th>Candidate Ref</th>\n",
       "      <th>DOJ Extended</th>\n",
       "      <th>Duration to accept offer</th>\n",
       "      <th>Notice period</th>\n",
       "      <th>Offered band</th>\n",
       "      <th>Pecent hike expected in CTC</th>\n",
       "      <th>Percent hike offered in CTC</th>\n",
       "      <th>Percent difference CTC</th>\n",
       "      <th>Joining Bonus</th>\n",
       "      <th>Candidate relocate actual</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Candidate Source</th>\n",
       "      <th>Rex in Yrs</th>\n",
       "      <th>LOB</th>\n",
       "      <th>Location</th>\n",
       "      <th>Age</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2110407</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-20.79</td>\n",
       "      <td>13.16</td>\n",
       "      <td>42.86</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2112838</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>42.84</td>\n",
       "      <td>42.84</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2115021</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>42.84</td>\n",
       "      <td>42.84</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>2115125</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>42.59</td>\n",
       "      <td>42.59</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>2117167</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>42.83</td>\n",
       "      <td>42.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SLNO  Candidate Ref  DOJ Extended  Duration to accept offer  Notice period  \\\n",
       "0     1        2110407             1                        14              1   \n",
       "1     3        2112838             0                         3              2   \n",
       "2     4        2115021             0                        26              1   \n",
       "3     5        2115125             1                         1              6   \n",
       "4     6        2117167             1                        17              1   \n",
       "\n",
       "   Offered band  Pecent hike expected in CTC  Percent hike offered in CTC  \\\n",
       "0             2                       -20.79                        13.16   \n",
       "1             2                        42.84                        42.84   \n",
       "2             2                        42.84                        42.84   \n",
       "3             2                        42.59                        42.59   \n",
       "4             1                        42.83                        42.83   \n",
       "\n",
       "   Percent difference CTC  Joining Bonus  Candidate relocate actual  Gender  \\\n",
       "0                   42.86              0                          0       1   \n",
       "1                    0.00              0                          0       0   \n",
       "2                    0.00              0                          0       0   \n",
       "3                    0.00              0                          0       0   \n",
       "4                    0.00              0                          0       0   \n",
       "\n",
       "   Candidate Source  Rex in Yrs  LOB  Location  Age  Status  \n",
       "0                 2           7    1         0   34       1  \n",
       "1                 2           4    0         0   27       1  \n",
       "2                 0           4    0         0   34       1  \n",
       "3                 0           6    0         0   34       1  \n",
       "4                 0           2    0         0   34       1  "
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input to the neural network\n",
    "train_x=train.iloc[:,2:17] #keeping only independent variables\n",
    "\n",
    "#changing data types to float64 to pass in the ANN\n",
    "for i in train_x.columns:\n",
    "    train_x[i]=train_x[i].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicted variable\n",
    "train_y=pd.DataFrame(train['Status'].astype('float64')) #Status is kept as the dependent variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/750\n",
      "11/11 [==============================] - 1s 22ms/step - loss: 0.8898 - val_loss: 0.9310\n",
      "Epoch 2/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.8811 - val_loss: 0.9152\n",
      "Epoch 3/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.8622 - val_loss: 0.8954\n",
      "Epoch 4/750\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.8424 - val_loss: 0.8693\n",
      "Epoch 5/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.8157 - val_loss: 0.8336\n",
      "Epoch 6/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.7799 - val_loss: 0.7845\n",
      "Epoch 7/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.7289 - val_loss: 0.7178\n",
      "Epoch 8/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.6651 - val_loss: 0.6292\n",
      "Epoch 9/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5889 - val_loss: 0.5160\n",
      "Epoch 10/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.5108 - val_loss: 0.4248\n",
      "Epoch 11/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4877 - val_loss: 0.4040\n",
      "Epoch 12/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4806 - val_loss: 0.4071\n",
      "Epoch 13/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4749 - val_loss: 0.4089\n",
      "Epoch 14/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4742 - val_loss: 0.4013\n",
      "Epoch 15/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4683 - val_loss: 0.3885\n",
      "Epoch 16/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4579 - val_loss: 0.3804\n",
      "Epoch 17/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4582 - val_loss: 0.3741\n",
      "Epoch 18/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4430 - val_loss: 0.3667\n",
      "Epoch 19/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4422 - val_loss: 0.3602\n",
      "Epoch 20/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4395 - val_loss: 0.3517\n",
      "Epoch 21/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4352 - val_loss: 0.3448\n",
      "Epoch 22/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4242 - val_loss: 0.3384\n",
      "Epoch 23/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4232 - val_loss: 0.3338\n",
      "Epoch 24/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4197 - val_loss: 0.3278\n",
      "Epoch 25/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4185 - val_loss: 0.3243\n",
      "Epoch 26/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4166 - val_loss: 0.3212\n",
      "Epoch 27/750\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.4084 - val_loss: 0.3188\n",
      "Epoch 28/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4069 - val_loss: 0.3180\n",
      "Epoch 29/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4073 - val_loss: 0.3167\n",
      "Epoch 30/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4070 - val_loss: 0.3164\n",
      "Epoch 31/750\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.4077 - val_loss: 0.3156\n",
      "Epoch 32/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.4101 - val_loss: 0.3152\n",
      "Epoch 33/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4056 - val_loss: 0.3149\n",
      "Epoch 34/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4029 - val_loss: 0.3144\n",
      "Epoch 35/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4043 - val_loss: 0.3145\n",
      "Epoch 36/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4045 - val_loss: 0.3138\n",
      "Epoch 37/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4050 - val_loss: 0.3135\n",
      "Epoch 38/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4067 - val_loss: 0.3134\n",
      "Epoch 39/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4047 - val_loss: 0.3128\n",
      "Epoch 40/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4021 - val_loss: 0.3125\n",
      "Epoch 41/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4089 - val_loss: 0.3122\n",
      "Epoch 42/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4036 - val_loss: 0.3119\n",
      "Epoch 43/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3987 - val_loss: 0.3116\n",
      "Epoch 44/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4032 - val_loss: 0.3113\n",
      "Epoch 45/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4051 - val_loss: 0.3112\n",
      "Epoch 46/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4051 - val_loss: 0.3108\n",
      "Epoch 47/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3997 - val_loss: 0.3106\n",
      "Epoch 48/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4030 - val_loss: 0.3105\n",
      "Epoch 49/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3948 - val_loss: 0.3100\n",
      "Epoch 50/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4019 - val_loss: 0.3099\n",
      "Epoch 51/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3961 - val_loss: 0.3098\n",
      "Epoch 52/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4052 - val_loss: 0.3095\n",
      "Epoch 53/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3974 - val_loss: 0.3094\n",
      "Epoch 54/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4049 - val_loss: 0.3091\n",
      "Epoch 55/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3967 - val_loss: 0.3093\n",
      "Epoch 56/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3986 - val_loss: 0.3087\n",
      "Epoch 57/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4002 - val_loss: 0.3088\n",
      "Epoch 58/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3949 - val_loss: 0.3087\n",
      "Epoch 59/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4011 - val_loss: 0.3085\n",
      "Epoch 60/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3949 - val_loss: 0.3084\n",
      "Epoch 61/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3976 - val_loss: 0.3082\n",
      "Epoch 62/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3989 - val_loss: 0.3084\n",
      "Epoch 63/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3983 - val_loss: 0.3081\n",
      "Epoch 64/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3970 - val_loss: 0.3080\n",
      "Epoch 65/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4006 - val_loss: 0.3082\n",
      "Epoch 66/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3961 - val_loss: 0.3080\n",
      "Epoch 67/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3969 - val_loss: 0.3081\n",
      "Epoch 68/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3994 - val_loss: 0.3082\n",
      "Epoch 69/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3979 - val_loss: 0.3081\n",
      "Epoch 70/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3964 - val_loss: 0.3078\n",
      "Epoch 71/750\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.3934 - val_loss: 0.3081\n",
      "Epoch 72/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3936 - val_loss: 0.3078\n",
      "Epoch 73/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3933 - val_loss: 0.3080\n",
      "Epoch 74/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3977 - val_loss: 0.3082\n",
      "Epoch 75/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3942 - val_loss: 0.3082\n",
      "Epoch 76/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3908 - val_loss: 0.3079\n",
      "Epoch 77/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3959 - val_loss: 0.3085\n",
      "Epoch 78/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3889 - val_loss: 0.3075\n",
      "Epoch 79/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3970 - val_loss: 0.3086\n",
      "Epoch 80/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3928 - val_loss: 0.3080\n",
      "Epoch 81/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3917 - val_loss: 0.3085\n",
      "Epoch 82/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3953 - val_loss: 0.3084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3945 - val_loss: 0.3085\n",
      "Epoch 84/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3950 - val_loss: 0.3085\n",
      "Epoch 85/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3957 - val_loss: 0.3094\n",
      "Epoch 86/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3938 - val_loss: 0.3083\n",
      "Epoch 87/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3993 - val_loss: 0.3096\n",
      "Epoch 88/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3937 - val_loss: 0.3083\n",
      "Epoch 89/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3992 - val_loss: 0.3115\n",
      "Epoch 90/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3962 - val_loss: 0.3084\n",
      "Epoch 91/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3932 - val_loss: 0.3095\n",
      "Epoch 92/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3918 - val_loss: 0.3095\n",
      "Epoch 93/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3979 - val_loss: 0.3095\n",
      "Epoch 94/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3948 - val_loss: 0.3100\n",
      "Epoch 95/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3912 - val_loss: 0.3090\n",
      "Epoch 96/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3937 - val_loss: 0.3092\n",
      "Epoch 97/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3967 - val_loss: 0.3102\n",
      "Epoch 98/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3936 - val_loss: 0.3098\n",
      "Epoch 99/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3923 - val_loss: 0.3101\n",
      "Epoch 100/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3902 - val_loss: 0.3091\n",
      "Epoch 101/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3948 - val_loss: 0.3107\n",
      "Epoch 102/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3925 - val_loss: 0.3094\n",
      "Epoch 103/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3916 - val_loss: 0.3097\n",
      "Epoch 104/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3943 - val_loss: 0.3111\n",
      "Epoch 105/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3911 - val_loss: 0.3089\n",
      "Epoch 106/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3939 - val_loss: 0.3128\n",
      "Epoch 107/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3893 - val_loss: 0.3089\n",
      "Epoch 108/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3858 - val_loss: 0.3108\n",
      "Epoch 109/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3932 - val_loss: 0.3114\n",
      "Epoch 110/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3962 - val_loss: 0.3098\n",
      "Epoch 111/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3927 - val_loss: 0.3098\n",
      "Epoch 112/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3942 - val_loss: 0.3117\n",
      "Epoch 113/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3906 - val_loss: 0.3099\n",
      "Epoch 114/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3950 - val_loss: 0.3123\n",
      "Epoch 115/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3925 - val_loss: 0.3095\n",
      "Epoch 116/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3935 - val_loss: 0.3121\n",
      "Epoch 117/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3913 - val_loss: 0.3103\n",
      "Epoch 118/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3896 - val_loss: 0.3105\n",
      "Epoch 119/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3908 - val_loss: 0.3116\n",
      "Epoch 120/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3960 - val_loss: 0.3110\n",
      "Epoch 121/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3921 - val_loss: 0.3113\n",
      "Epoch 122/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3930 - val_loss: 0.3103\n",
      "Epoch 123/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3887 - val_loss: 0.3107\n",
      "Epoch 124/750\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.3910 - val_loss: 0.3107\n",
      "Epoch 125/750\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.3927 - val_loss: 0.3106\n",
      "Epoch 126/750\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.3922 - val_loss: 0.3099\n",
      "Epoch 127/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3935 - val_loss: 0.3115\n",
      "Epoch 128/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3926 - val_loss: 0.3102\n",
      "Epoch 129/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3921 - val_loss: 0.3123\n",
      "Epoch 130/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3942 - val_loss: 0.3105\n",
      "Epoch 131/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3903 - val_loss: 0.3109\n",
      "Epoch 132/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3954 - val_loss: 0.3136\n",
      "Epoch 133/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3910 - val_loss: 0.3091\n",
      "Epoch 134/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3942 - val_loss: 0.3141\n",
      "Epoch 135/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3934 - val_loss: 0.3100\n",
      "Epoch 136/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3882 - val_loss: 0.3103\n",
      "Epoch 137/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3908 - val_loss: 0.3111\n",
      "Epoch 138/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3921 - val_loss: 0.3115\n",
      "Epoch 139/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3911 - val_loss: 0.3103\n",
      "Epoch 140/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3860 - val_loss: 0.3100\n",
      "Epoch 141/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3857 - val_loss: 0.3105\n",
      "Epoch 142/750\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.3931 - val_loss: 0.3118\n",
      "Epoch 143/750\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.3923 - val_loss: 0.3096\n",
      "Epoch 144/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3879 - val_loss: 0.3114\n",
      "Epoch 145/750\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.3913 - val_loss: 0.3107\n",
      "Epoch 146/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3902 - val_loss: 0.3101\n",
      "Epoch 147/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3875 - val_loss: 0.3102\n",
      "Epoch 148/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3920 - val_loss: 0.3108\n",
      "Epoch 149/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3881 - val_loss: 0.3097\n",
      "Epoch 150/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3922 - val_loss: 0.3116\n",
      "Epoch 151/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3901 - val_loss: 0.3099\n",
      "Epoch 152/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3906 - val_loss: 0.3111\n",
      "Epoch 153/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3884 - val_loss: 0.3094\n",
      "Epoch 154/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3918 - val_loss: 0.3120\n",
      "Epoch 155/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3930 - val_loss: 0.3103\n",
      "Epoch 156/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3825 - val_loss: 0.3097\n",
      "Epoch 157/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3927 - val_loss: 0.3118\n",
      "Epoch 158/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3920 - val_loss: 0.3096\n",
      "Epoch 159/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3857 - val_loss: 0.3101\n",
      "Epoch 160/750\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.3950 - val_loss: 0.3112\n",
      "Epoch 161/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3931 - val_loss: 0.3095\n",
      "Epoch 162/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3828 - val_loss: 0.3097\n",
      "Epoch 163/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3925 - val_loss: 0.3108\n",
      "Epoch 164/750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3928 - val_loss: 0.3102\n",
      "Epoch 165/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3910 - val_loss: 0.3098\n",
      "Epoch 166/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3843 - val_loss: 0.3096\n",
      "Epoch 167/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3933 - val_loss: 0.3113\n",
      "Epoch 168/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3884 - val_loss: 0.3089\n",
      "Epoch 169/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3912 - val_loss: 0.3109\n",
      "Epoch 170/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3901 - val_loss: 0.3089\n",
      "Epoch 171/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3961 - val_loss: 0.3124\n",
      "Epoch 172/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3880 - val_loss: 0.3088\n",
      "Epoch 173/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3946 - val_loss: 0.3116\n",
      "Epoch 174/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3902 - val_loss: 0.3088\n",
      "Epoch 175/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3883 - val_loss: 0.3097\n",
      "Epoch 176/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3891 - val_loss: 0.3102\n",
      "Epoch 177/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3887 - val_loss: 0.3103\n",
      "Epoch 178/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3868 - val_loss: 0.3091\n",
      "Epoch 179/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3932 - val_loss: 0.3100\n",
      "Epoch 180/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3835 - val_loss: 0.3093\n",
      "Epoch 181/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3888 - val_loss: 0.3093\n",
      "Epoch 182/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3891 - val_loss: 0.3101\n",
      "Epoch 183/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3922 - val_loss: 0.3098\n",
      "Epoch 184/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3867 - val_loss: 0.3091\n",
      "Epoch 185/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3874 - val_loss: 0.3096\n",
      "Epoch 186/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3920 - val_loss: 0.3101\n",
      "Epoch 187/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3923 - val_loss: 0.3104\n",
      "Epoch 188/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3900 - val_loss: 0.3093\n",
      "Epoch 189/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3906 - val_loss: 0.3098\n",
      "Epoch 190/750\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.3900 - val_loss: 0.3094\n",
      "Epoch 191/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3895 - val_loss: 0.3098\n",
      "Epoch 192/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3866 - val_loss: 0.3091\n",
      "Epoch 193/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3912 - val_loss: 0.3104\n",
      "Epoch 194/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3887 - val_loss: 0.3088\n",
      "Epoch 195/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3894 - val_loss: 0.3093\n",
      "Epoch 196/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3855 - val_loss: 0.3081\n",
      "Epoch 197/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3961 - val_loss: 0.3129\n",
      "Epoch 198/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3902 - val_loss: 0.3083\n",
      "Epoch 199/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3853 - val_loss: 0.3096\n",
      "Epoch 200/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3896 - val_loss: 0.3090\n",
      "Epoch 201/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3914 - val_loss: 0.3095\n",
      "Epoch 202/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3849 - val_loss: 0.3087\n",
      "Epoch 203/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3883 - val_loss: 0.3097\n",
      "Epoch 204/750\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.3878 - val_loss: 0.3091\n",
      "Epoch 205/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3843 - val_loss: 0.3082\n",
      "Epoch 206/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3926 - val_loss: 0.3103\n",
      "Epoch 207/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3925 - val_loss: 0.3094\n",
      "Epoch 208/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3874 - val_loss: 0.3082\n",
      "Epoch 209/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3862 - val_loss: 0.3104\n",
      "Epoch 210/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3920 - val_loss: 0.3083\n",
      "Epoch 211/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3919 - val_loss: 0.3103\n",
      "Epoch 212/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3917 - val_loss: 0.3086\n",
      "Epoch 213/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3929 - val_loss: 0.3097\n",
      "Epoch 214/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3918 - val_loss: 0.3087\n",
      "Epoch 215/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3927 - val_loss: 0.3102\n",
      "Epoch 216/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3919 - val_loss: 0.3086\n",
      "Epoch 217/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3888 - val_loss: 0.3093\n",
      "Epoch 218/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3912 - val_loss: 0.3100\n",
      "Epoch 219/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3916 - val_loss: 0.3088\n",
      "Epoch 220/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3845 - val_loss: 0.3084\n",
      "Epoch 221/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3935 - val_loss: 0.3098\n",
      "Epoch 222/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3952 - val_loss: 0.3086\n",
      "Epoch 223/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3928 - val_loss: 0.3100\n",
      "Epoch 224/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3889 - val_loss: 0.3083\n",
      "Epoch 225/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3879 - val_loss: 0.3092\n",
      "Epoch 226/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3920 - val_loss: 0.3094\n",
      "Epoch 227/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3861 - val_loss: 0.3082\n",
      "Epoch 228/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3878 - val_loss: 0.3091\n",
      "Epoch 229/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3943 - val_loss: 0.3095\n",
      "Epoch 230/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3919 - val_loss: 0.3089\n",
      "Epoch 231/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3870 - val_loss: 0.3082\n",
      "Epoch 232/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3868 - val_loss: 0.3088\n",
      "Epoch 233/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3883 - val_loss: 0.3086\n",
      "Epoch 234/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3872 - val_loss: 0.3085\n",
      "Epoch 235/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3922 - val_loss: 0.3097\n",
      "Epoch 236/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3892 - val_loss: 0.3081\n",
      "Epoch 237/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3910 - val_loss: 0.3107\n",
      "Epoch 238/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3923 - val_loss: 0.3088\n",
      "Epoch 239/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3892 - val_loss: 0.3085\n",
      "Epoch 240/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3869 - val_loss: 0.3087\n",
      "Epoch 241/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3822 - val_loss: 0.3080\n",
      "Epoch 242/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3869 - val_loss: 0.3090\n",
      "Epoch 243/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3885 - val_loss: 0.3085\n",
      "Epoch 244/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3830 - val_loss: 0.3082\n",
      "Epoch 245/750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3858 - val_loss: 0.3095\n",
      "Epoch 246/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3957 - val_loss: 0.3088\n",
      "Epoch 247/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3890 - val_loss: 0.3081\n",
      "Epoch 248/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3844 - val_loss: 0.3084\n",
      "Epoch 249/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3884 - val_loss: 0.3087\n",
      "Epoch 250/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3832 - val_loss: 0.3083\n",
      "Epoch 251/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3875 - val_loss: 0.3087\n",
      "Epoch 252/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3883 - val_loss: 0.3083\n",
      "Epoch 253/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3890 - val_loss: 0.3095\n",
      "Epoch 254/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3895 - val_loss: 0.3081\n",
      "Epoch 255/750\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.3864 - val_loss: 0.3084\n",
      "Epoch 256/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3938 - val_loss: 0.3098\n",
      "Epoch 257/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3893 - val_loss: 0.3084\n",
      "Epoch 258/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3864 - val_loss: 0.3080\n",
      "Epoch 259/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3907 - val_loss: 0.3103\n",
      "Epoch 260/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3923 - val_loss: 0.3080\n",
      "Epoch 261/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3852 - val_loss: 0.3079\n",
      "Epoch 262/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3844 - val_loss: 0.3091\n",
      "Epoch 263/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3896 - val_loss: 0.3081\n",
      "Epoch 264/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3911 - val_loss: 0.3084\n",
      "Epoch 265/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3898 - val_loss: 0.3080\n",
      "Epoch 266/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3878 - val_loss: 0.3081\n",
      "Epoch 267/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3842 - val_loss: 0.3081\n",
      "Epoch 268/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3910 - val_loss: 0.3090\n",
      "Epoch 269/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3913 - val_loss: 0.3086\n",
      "Epoch 270/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3891 - val_loss: 0.3079\n",
      "Epoch 271/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3907 - val_loss: 0.3086\n",
      "Epoch 272/750\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.3843 - val_loss: 0.3080\n",
      "Epoch 273/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3902 - val_loss: 0.3081\n",
      "Epoch 274/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3864 - val_loss: 0.3082\n",
      "Epoch 275/750\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.3864 - val_loss: 0.3077\n",
      "Epoch 276/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3832 - val_loss: 0.3079\n",
      "Epoch 277/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3859 - val_loss: 0.3086\n",
      "Epoch 278/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3852 - val_loss: 0.3082\n",
      "Epoch 279/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3920 - val_loss: 0.3087\n",
      "Epoch 280/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3942 - val_loss: 0.3084\n",
      "Epoch 281/750\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.3868 - val_loss: 0.3079\n",
      "Epoch 282/750\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.3859 - val_loss: 0.3085\n",
      "Epoch 283/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3892 - val_loss: 0.3079\n",
      "Epoch 284/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3854 - val_loss: 0.3082\n",
      "Epoch 285/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3864 - val_loss: 0.3082\n",
      "Epoch 286/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3895 - val_loss: 0.3084\n",
      "Epoch 287/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3860 - val_loss: 0.3079\n",
      "Epoch 288/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3855 - val_loss: 0.3081\n",
      "Epoch 289/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3907 - val_loss: 0.3090\n",
      "Epoch 290/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3873 - val_loss: 0.3079\n",
      "Epoch 291/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3891 - val_loss: 0.3087\n",
      "Epoch 292/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3887 - val_loss: 0.3078\n",
      "Epoch 293/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3859 - val_loss: 0.3079\n",
      "Epoch 294/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3867 - val_loss: 0.3080\n",
      "Epoch 295/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3865 - val_loss: 0.3082\n",
      "Epoch 296/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3908 - val_loss: 0.3082\n",
      "Epoch 297/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3844 - val_loss: 0.3078\n",
      "Epoch 298/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3813 - val_loss: 0.3079\n",
      "Epoch 299/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3861 - val_loss: 0.3086\n",
      "Epoch 300/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3849 - val_loss: 0.3079\n",
      "Epoch 301/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3875 - val_loss: 0.3085\n",
      "Epoch 302/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3852 - val_loss: 0.3077\n",
      "Epoch 303/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3884 - val_loss: 0.3083\n",
      "Epoch 304/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3875 - val_loss: 0.3077\n",
      "Epoch 305/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3883 - val_loss: 0.3080\n",
      "Epoch 306/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3870 - val_loss: 0.3077\n",
      "Epoch 307/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3868 - val_loss: 0.3079\n",
      "Epoch 308/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3936 - val_loss: 0.3094\n",
      "Epoch 309/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3879 - val_loss: 0.3080\n",
      "Epoch 310/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3861 - val_loss: 0.3082\n",
      "Epoch 311/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3866 - val_loss: 0.3080\n",
      "Epoch 312/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3931 - val_loss: 0.3083\n",
      "Epoch 313/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3866 - val_loss: 0.3078\n",
      "Epoch 314/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3873 - val_loss: 0.3080\n",
      "Epoch 315/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3933 - val_loss: 0.3092\n",
      "Epoch 316/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3840 - val_loss: 0.3081\n",
      "Epoch 317/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3900 - val_loss: 0.3096\n",
      "Epoch 318/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3872 - val_loss: 0.3078\n",
      "Epoch 319/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3880 - val_loss: 0.3078\n",
      "Epoch 320/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3928 - val_loss: 0.3089\n",
      "Epoch 321/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3890 - val_loss: 0.3080\n",
      "Epoch 322/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3874 - val_loss: 0.3077\n",
      "Epoch 323/750\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.3908 - val_loss: 0.3080\n",
      "Epoch 324/750\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.3848 - val_loss: 0.3077\n",
      "Epoch 325/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3903 - val_loss: 0.3082\n",
      "Epoch 326/750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3835 - val_loss: 0.3078\n",
      "Epoch 327/750\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.3917 - val_loss: 0.3083\n",
      "Epoch 328/750\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.3861 - val_loss: 0.3077\n",
      "Epoch 329/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3913 - val_loss: 0.3082\n",
      "Epoch 330/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3884 - val_loss: 0.3078\n",
      "Epoch 331/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3873 - val_loss: 0.3079\n",
      "Epoch 332/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3889 - val_loss: 0.3077\n",
      "Epoch 333/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3884 - val_loss: 0.3079\n",
      "Epoch 334/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3856 - val_loss: 0.3077\n",
      "Epoch 335/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3841 - val_loss: 0.3078\n",
      "Epoch 336/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3848 - val_loss: 0.3077\n",
      "Epoch 337/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3863 - val_loss: 0.3077\n",
      "Epoch 338/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3867 - val_loss: 0.3081\n",
      "Epoch 339/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3892 - val_loss: 0.3077\n",
      "Epoch 340/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3886 - val_loss: 0.3076\n",
      "Epoch 341/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3876 - val_loss: 0.3078\n",
      "Epoch 342/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3824 - val_loss: 0.3077\n",
      "Epoch 343/750\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.3880 - val_loss: 0.3080\n",
      "Epoch 344/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3871 - val_loss: 0.3078\n",
      "Epoch 345/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3897 - val_loss: 0.3077\n",
      "Epoch 346/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3881 - val_loss: 0.3080\n",
      "Epoch 347/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3934 - val_loss: 0.3077\n",
      "Epoch 348/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3893 - val_loss: 0.3078\n",
      "Epoch 349/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3848 - val_loss: 0.3078\n",
      "Epoch 350/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3797 - val_loss: 0.3076\n",
      "Epoch 351/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3845 - val_loss: 0.3077\n",
      "Epoch 352/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3827 - val_loss: 0.3078\n",
      "Epoch 353/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3888 - val_loss: 0.3079\n",
      "Epoch 354/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3883 - val_loss: 0.3077\n",
      "Epoch 355/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3864 - val_loss: 0.3077\n",
      "Epoch 356/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3867 - val_loss: 0.3079\n",
      "Epoch 357/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3909 - val_loss: 0.3077\n",
      "Epoch 358/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3857 - val_loss: 0.3077\n",
      "Epoch 359/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3881 - val_loss: 0.3083\n",
      "Epoch 360/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3883 - val_loss: 0.3078\n",
      "Epoch 361/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3889 - val_loss: 0.3077\n",
      "Epoch 362/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3852 - val_loss: 0.3077\n",
      "Epoch 363/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3830 - val_loss: 0.3079\n",
      "Epoch 364/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3866 - val_loss: 0.3079\n",
      "Epoch 365/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3886 - val_loss: 0.3079\n",
      "Epoch 366/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3832 - val_loss: 0.3081\n",
      "Epoch 367/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3881 - val_loss: 0.3075\n",
      "Epoch 368/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3892 - val_loss: 0.3077\n",
      "Epoch 369/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3842 - val_loss: 0.3078\n",
      "Epoch 370/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3876 - val_loss: 0.3078\n",
      "Epoch 371/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3907 - val_loss: 0.3078\n",
      "Epoch 372/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3884 - val_loss: 0.3077\n",
      "Epoch 373/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3862 - val_loss: 0.3076\n",
      "Epoch 374/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3847 - val_loss: 0.3078\n",
      "Epoch 375/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3889 - val_loss: 0.3079\n",
      "Epoch 376/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3899 - val_loss: 0.3080\n",
      "Epoch 377/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3919 - val_loss: 0.3077\n",
      "Epoch 378/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3913 - val_loss: 0.3080\n",
      "Epoch 379/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3866 - val_loss: 0.3078\n",
      "Epoch 380/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3862 - val_loss: 0.3077\n",
      "Epoch 381/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3922 - val_loss: 0.3086\n",
      "Epoch 382/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3855 - val_loss: 0.3081\n",
      "Epoch 383/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3892 - val_loss: 0.3078\n",
      "Epoch 384/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3861 - val_loss: 0.3078\n",
      "Epoch 385/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3867 - val_loss: 0.3075\n",
      "Epoch 386/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3933 - val_loss: 0.3077\n",
      "Epoch 387/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3798 - val_loss: 0.3078\n",
      "Epoch 388/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3864 - val_loss: 0.3078\n",
      "Epoch 389/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3835 - val_loss: 0.3078\n",
      "Epoch 390/750\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3866 - val_loss: 0.3077\n",
      "Epoch 391/750\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.3897 - val_loss: 0.3076\n",
      "Epoch 392/750\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.347 - 0s 6ms/step - loss: 0.3773 - val_loss: 0.3078\n",
      "Epoch 393/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3853 - val_loss: 0.3076\n",
      "Epoch 394/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3828 - val_loss: 0.3078\n",
      "Epoch 395/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3888 - val_loss: 0.3078\n",
      "Epoch 396/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3905 - val_loss: 0.3077\n",
      "Epoch 397/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3895 - val_loss: 0.3076\n",
      "Epoch 398/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3812 - val_loss: 0.3078\n",
      "Epoch 399/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3852 - val_loss: 0.3079\n",
      "Epoch 400/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3852 - val_loss: 0.3077\n",
      "Epoch 401/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3845 - val_loss: 0.3077\n",
      "Epoch 402/750\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.3881 - val_loss: 0.3077\n",
      "Epoch 403/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3888 - val_loss: 0.3077\n",
      "Epoch 404/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3904 - val_loss: 0.3077\n",
      "Epoch 405/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3802 - val_loss: 0.3079\n",
      "Epoch 406/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3800 - val_loss: 0.3076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 407/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3812 - val_loss: 0.3077\n",
      "Epoch 408/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3847 - val_loss: 0.3077\n",
      "Epoch 409/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3819 - val_loss: 0.3078\n",
      "Epoch 410/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3844 - val_loss: 0.3076\n",
      "Epoch 411/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3853 - val_loss: 0.3079\n",
      "Epoch 412/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3908 - val_loss: 0.3078\n",
      "Epoch 413/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3882 - val_loss: 0.3077\n",
      "Epoch 414/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3884 - val_loss: 0.3077\n",
      "Epoch 415/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3858 - val_loss: 0.3076\n",
      "Epoch 416/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3902 - val_loss: 0.3081\n",
      "Epoch 417/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3914 - val_loss: 0.3076\n",
      "Epoch 418/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3889 - val_loss: 0.3077\n",
      "Epoch 419/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3832 - val_loss: 0.3077\n",
      "Epoch 420/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3889 - val_loss: 0.3076\n",
      "Epoch 421/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3899 - val_loss: 0.3077\n",
      "Epoch 422/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3879 - val_loss: 0.3075\n",
      "Epoch 423/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3822 - val_loss: 0.3079\n",
      "Epoch 424/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3883 - val_loss: 0.3078\n",
      "Epoch 425/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3800 - val_loss: 0.3085\n",
      "Epoch 426/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3928 - val_loss: 0.3086\n",
      "Epoch 427/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3873 - val_loss: 0.3090\n",
      "Epoch 428/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3858 - val_loss: 0.3077\n",
      "Epoch 429/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3842 - val_loss: 0.3079\n",
      "Epoch 430/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3828 - val_loss: 0.3076\n",
      "Epoch 431/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3860 - val_loss: 0.3076\n",
      "Epoch 432/750\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.394 - 0s 6ms/step - loss: 0.3838 - val_loss: 0.3077\n",
      "Epoch 433/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3891 - val_loss: 0.3078\n",
      "Epoch 434/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3831 - val_loss: 0.3093\n",
      "Epoch 435/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3899 - val_loss: 0.3077\n",
      "Epoch 436/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3850 - val_loss: 0.3082\n",
      "Epoch 437/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3885 - val_loss: 0.3076\n",
      "Epoch 438/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3899 - val_loss: 0.3077\n",
      "Epoch 439/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3884 - val_loss: 0.3074\n",
      "Epoch 440/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3858 - val_loss: 0.3078\n",
      "Epoch 441/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3857 - val_loss: 0.3076\n",
      "Epoch 442/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3859 - val_loss: 0.3075\n",
      "Epoch 443/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3910 - val_loss: 0.3075\n",
      "Epoch 444/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3836 - val_loss: 0.3083\n",
      "Epoch 445/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3882 - val_loss: 0.3077\n",
      "Epoch 446/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3851 - val_loss: 0.3080\n",
      "Epoch 447/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3808 - val_loss: 0.3075\n",
      "Epoch 448/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3906 - val_loss: 0.3076\n",
      "Epoch 449/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3870 - val_loss: 0.3075\n",
      "Epoch 450/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3842 - val_loss: 0.3074\n",
      "Epoch 451/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3879 - val_loss: 0.3075\n",
      "Epoch 452/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3872 - val_loss: 0.3076\n",
      "Epoch 453/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3876 - val_loss: 0.3075\n",
      "Epoch 454/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3870 - val_loss: 0.3075\n",
      "Epoch 455/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3861 - val_loss: 0.3077\n",
      "Epoch 456/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3874 - val_loss: 0.3075\n",
      "Epoch 457/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3853 - val_loss: 0.3077\n",
      "Epoch 458/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3852 - val_loss: 0.3079\n",
      "Epoch 459/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3859 - val_loss: 0.3075\n",
      "Epoch 460/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3862 - val_loss: 0.3077\n",
      "Epoch 461/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3875 - val_loss: 0.3079\n",
      "Epoch 462/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3804 - val_loss: 0.3077\n",
      "Epoch 463/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3824 - val_loss: 0.3075\n",
      "Epoch 464/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3826 - val_loss: 0.3081\n",
      "Epoch 465/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3919 - val_loss: 0.3081\n",
      "Epoch 466/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3873 - val_loss: 0.3077\n",
      "Epoch 467/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3810 - val_loss: 0.3077\n",
      "Epoch 468/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3871 - val_loss: 0.3075\n",
      "Epoch 469/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3820 - val_loss: 0.3076\n",
      "Epoch 470/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3788 - val_loss: 0.3077\n",
      "Epoch 471/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3860 - val_loss: 0.3075\n",
      "Epoch 472/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3818 - val_loss: 0.3091\n",
      "Epoch 473/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3857 - val_loss: 0.3075\n",
      "Epoch 474/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3875 - val_loss: 0.3074\n",
      "Epoch 475/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3836 - val_loss: 0.3079\n",
      "Epoch 476/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3912 - val_loss: 0.3076\n",
      "Epoch 477/750\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.3865 - val_loss: 0.3087\n",
      "Epoch 478/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3890 - val_loss: 0.3076\n",
      "Epoch 479/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3886 - val_loss: 0.3078\n",
      "Epoch 480/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3900 - val_loss: 0.3075\n",
      "Epoch 481/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3859 - val_loss: 0.3078\n",
      "Epoch 482/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3888 - val_loss: 0.3073\n",
      "Epoch 483/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3796 - val_loss: 0.3095\n",
      "Epoch 484/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3846 - val_loss: 0.3074\n",
      "Epoch 485/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3853 - val_loss: 0.3074\n",
      "Epoch 486/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3821 - val_loss: 0.3087\n",
      "Epoch 487/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3865 - val_loss: 0.3075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 488/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3817 - val_loss: 0.3077\n",
      "Epoch 489/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3804 - val_loss: 0.3084\n",
      "Epoch 490/750\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.3850 - val_loss: 0.3075\n",
      "Epoch 491/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3844 - val_loss: 0.3077\n",
      "Epoch 492/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3906 - val_loss: 0.3075\n",
      "Epoch 493/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3784 - val_loss: 0.3113\n",
      "Epoch 494/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3888 - val_loss: 0.3077\n",
      "Epoch 495/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3834 - val_loss: 0.3085\n",
      "Epoch 496/750\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.3898 - val_loss: 0.3071\n",
      "Epoch 497/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3867 - val_loss: 0.3073\n",
      "Epoch 498/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3892 - val_loss: 0.3072\n",
      "Epoch 499/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3828 - val_loss: 0.3082\n",
      "Epoch 500/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3905 - val_loss: 0.3072\n",
      "Epoch 501/750\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.3855 - val_loss: 0.3078\n",
      "Epoch 502/750\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.3871 - val_loss: 0.3075\n",
      "Epoch 503/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3817 - val_loss: 0.3075\n",
      "Epoch 504/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3852 - val_loss: 0.3075\n",
      "Epoch 505/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3881 - val_loss: 0.3074\n",
      "Epoch 506/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3892 - val_loss: 0.3074\n",
      "Epoch 507/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3839 - val_loss: 0.3082\n",
      "Epoch 508/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3847 - val_loss: 0.3072\n",
      "Epoch 509/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3863 - val_loss: 0.3074\n",
      "Epoch 510/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3833 - val_loss: 0.3082\n",
      "Epoch 511/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3817 - val_loss: 0.3075\n",
      "Epoch 512/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3793 - val_loss: 0.3079\n",
      "Epoch 513/750\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.375 - 0s 6ms/step - loss: 0.3850 - val_loss: 0.3073\n",
      "Epoch 514/750\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.3827 - val_loss: 0.3078\n",
      "Epoch 515/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3884 - val_loss: 0.3072\n",
      "Epoch 516/750\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.3856 - val_loss: 0.3080\n",
      "Epoch 517/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3824 - val_loss: 0.3078\n",
      "Epoch 518/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3885 - val_loss: 0.3072\n",
      "Epoch 519/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3836 - val_loss: 0.3080\n",
      "Epoch 520/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3831 - val_loss: 0.3078\n",
      "Epoch 521/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3830 - val_loss: 0.3073\n",
      "Epoch 522/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3853 - val_loss: 0.3079\n",
      "Epoch 523/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3836 - val_loss: 0.3073\n",
      "Epoch 524/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3803 - val_loss: 0.3089\n",
      "Epoch 525/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3876 - val_loss: 0.3073\n",
      "Epoch 526/750\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.368 - 0s 6ms/step - loss: 0.3819 - val_loss: 0.3077\n",
      "Epoch 527/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3865 - val_loss: 0.3075\n",
      "Epoch 528/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3815 - val_loss: 0.3089\n",
      "Epoch 529/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3840 - val_loss: 0.3073\n",
      "Epoch 530/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3833 - val_loss: 0.3077\n",
      "Epoch 531/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3875 - val_loss: 0.3075\n",
      "Epoch 532/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3867 - val_loss: 0.3087\n",
      "Epoch 533/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3808 - val_loss: 0.3077\n",
      "Epoch 534/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3777 - val_loss: 0.3078\n",
      "Epoch 535/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3812 - val_loss: 0.3075\n",
      "Epoch 536/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3865 - val_loss: 0.3075\n",
      "Epoch 537/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3829 - val_loss: 0.3079\n",
      "Epoch 538/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3921 - val_loss: 0.3073\n",
      "Epoch 539/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3886 - val_loss: 0.3087\n",
      "Epoch 540/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3814 - val_loss: 0.3078\n",
      "Epoch 541/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3819 - val_loss: 0.3074\n",
      "Epoch 542/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3844 - val_loss: 0.3079\n",
      "Epoch 543/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3866 - val_loss: 0.3074\n",
      "Epoch 544/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3879 - val_loss: 0.3073\n",
      "Epoch 545/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3913 - val_loss: 0.3077\n",
      "Epoch 546/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3818 - val_loss: 0.3077\n",
      "Epoch 547/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3817 - val_loss: 0.3085\n",
      "Epoch 548/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3845 - val_loss: 0.3074\n",
      "Epoch 549/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3894 - val_loss: 0.3073\n",
      "Epoch 550/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3839 - val_loss: 0.3079\n",
      "Epoch 551/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3892 - val_loss: 0.3074\n",
      "Epoch 552/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3771 - val_loss: 0.3098\n",
      "Epoch 553/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3806 - val_loss: 0.3076\n",
      "Epoch 554/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3847 - val_loss: 0.3072\n",
      "Epoch 555/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3832 - val_loss: 0.3094\n",
      "Epoch 556/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3843 - val_loss: 0.3075\n",
      "Epoch 557/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3836 - val_loss: 0.3076\n",
      "Epoch 558/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3906 - val_loss: 0.3074\n",
      "Epoch 559/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3850 - val_loss: 0.3078\n",
      "Epoch 560/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3819 - val_loss: 0.3081\n",
      "Epoch 561/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3868 - val_loss: 0.3070\n",
      "Epoch 562/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3785 - val_loss: 0.3083\n",
      "Epoch 563/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3882 - val_loss: 0.3075\n",
      "Epoch 564/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3808 - val_loss: 0.3096\n",
      "Epoch 565/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3869 - val_loss: 0.3075\n",
      "Epoch 566/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3874 - val_loss: 0.3090\n",
      "Epoch 567/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3866 - val_loss: 0.3075\n",
      "Epoch 568/750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3847 - val_loss: 0.3078\n",
      "Epoch 569/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3824 - val_loss: 0.3082\n",
      "Epoch 570/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3874 - val_loss: 0.3076\n",
      "Epoch 571/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3864 - val_loss: 0.3077\n",
      "Epoch 572/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3813 - val_loss: 0.3082\n",
      "Epoch 573/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3794 - val_loss: 0.3081\n",
      "Epoch 574/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3853 - val_loss: 0.3076\n",
      "Epoch 575/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3859 - val_loss: 0.3078\n",
      "Epoch 576/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3824 - val_loss: 0.3084\n",
      "Epoch 577/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3876 - val_loss: 0.3075\n",
      "Epoch 578/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3799 - val_loss: 0.3101\n",
      "Epoch 579/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3864 - val_loss: 0.3076\n",
      "Epoch 580/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3849 - val_loss: 0.3080\n",
      "Epoch 581/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3779 - val_loss: 0.3081\n",
      "Epoch 582/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3842 - val_loss: 0.3080\n",
      "Epoch 583/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3860 - val_loss: 0.3078\n",
      "Epoch 584/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3848 - val_loss: 0.3082\n",
      "Epoch 585/750\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.3859 - val_loss: 0.3079\n",
      "Epoch 586/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3797 - val_loss: 0.3119\n",
      "Epoch 587/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3869 - val_loss: 0.3084\n",
      "Epoch 588/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3831 - val_loss: 0.3103\n",
      "Epoch 589/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3880 - val_loss: 0.3081\n",
      "Epoch 590/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3806 - val_loss: 0.3097\n",
      "Epoch 591/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3902 - val_loss: 0.3077\n",
      "Epoch 592/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3886 - val_loss: 0.3081\n",
      "Epoch 593/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3864 - val_loss: 0.3081\n",
      "Epoch 594/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3836 - val_loss: 0.3084\n",
      "Epoch 595/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3739 - val_loss: 0.3104\n",
      "Epoch 596/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3843 - val_loss: 0.3084\n",
      "Epoch 597/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3819 - val_loss: 0.3090\n",
      "Epoch 598/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3797 - val_loss: 0.3083\n",
      "Epoch 599/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3839 - val_loss: 0.3080\n",
      "Epoch 600/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3856 - val_loss: 0.3083\n",
      "Epoch 601/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3813 - val_loss: 0.3083\n",
      "Epoch 602/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3825 - val_loss: 0.3085\n",
      "Epoch 603/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3832 - val_loss: 0.3080\n",
      "Epoch 604/750\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.3802 - val_loss: 0.3089\n",
      "Epoch 605/750\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.3836 - val_loss: 0.3078\n",
      "Epoch 606/750\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.3826 - val_loss: 0.3080\n",
      "Epoch 607/750\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.3840 - val_loss: 0.3083\n",
      "Epoch 608/750\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.3870 - val_loss: 0.3079\n",
      "Epoch 609/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3840 - val_loss: 0.3084\n",
      "Epoch 610/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3812 - val_loss: 0.3098\n",
      "Epoch 611/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3869 - val_loss: 0.3082\n",
      "Epoch 612/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3821 - val_loss: 0.3105\n",
      "Epoch 613/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3861 - val_loss: 0.3081\n",
      "Epoch 614/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3815 - val_loss: 0.3090\n",
      "Epoch 615/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3866 - val_loss: 0.3091\n",
      "Epoch 616/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3786 - val_loss: 0.3096\n",
      "Epoch 617/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3793 - val_loss: 0.3084\n",
      "Epoch 618/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3839 - val_loss: 0.3081\n",
      "Epoch 619/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3847 - val_loss: 0.3084\n",
      "Epoch 620/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3851 - val_loss: 0.3088\n",
      "Epoch 621/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3857 - val_loss: 0.3090\n",
      "Epoch 622/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3876 - val_loss: 0.3082\n",
      "Epoch 623/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3853 - val_loss: 0.3086\n",
      "Epoch 624/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3828 - val_loss: 0.3083\n",
      "Epoch 625/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3821 - val_loss: 0.3088\n",
      "Epoch 626/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3782 - val_loss: 0.3095\n",
      "Epoch 627/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3857 - val_loss: 0.3083\n",
      "Epoch 628/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3812 - val_loss: 0.3084\n",
      "Epoch 629/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3818 - val_loss: 0.3098\n",
      "Epoch 630/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3852 - val_loss: 0.3083\n",
      "Epoch 631/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3813 - val_loss: 0.3098\n",
      "Epoch 632/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3797 - val_loss: 0.3096\n",
      "Epoch 633/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3817 - val_loss: 0.3087\n",
      "Epoch 634/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3855 - val_loss: 0.3080\n",
      "Epoch 635/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3814 - val_loss: 0.3097\n",
      "Epoch 636/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3806 - val_loss: 0.3090\n",
      "Epoch 637/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3786 - val_loss: 0.3102\n",
      "Epoch 638/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3859 - val_loss: 0.3081\n",
      "Epoch 639/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3789 - val_loss: 0.3097\n",
      "Epoch 640/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3843 - val_loss: 0.3087\n",
      "Epoch 641/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3830 - val_loss: 0.3085\n",
      "Epoch 642/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3809 - val_loss: 0.3095\n",
      "Epoch 643/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3817 - val_loss: 0.3087\n",
      "Epoch 644/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3806 - val_loss: 0.3087\n",
      "Epoch 645/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3832 - val_loss: 0.3098\n",
      "Epoch 646/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3795 - val_loss: 0.3095\n",
      "Epoch 647/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3812 - val_loss: 0.3082\n",
      "Epoch 648/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3844 - val_loss: 0.3087\n",
      "Epoch 649/750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3821 - val_loss: 0.3089\n",
      "Epoch 650/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3852 - val_loss: 0.3088\n",
      "Epoch 651/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3874 - val_loss: 0.3082\n",
      "Epoch 652/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3857 - val_loss: 0.3091\n",
      "Epoch 653/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3837 - val_loss: 0.3086\n",
      "Epoch 654/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3796 - val_loss: 0.3101\n",
      "Epoch 655/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3834 - val_loss: 0.3084\n",
      "Epoch 656/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3841 - val_loss: 0.3098\n",
      "Epoch 657/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3818 - val_loss: 0.3084\n",
      "Epoch 658/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3854 - val_loss: 0.3090\n",
      "Epoch 659/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3815 - val_loss: 0.3097\n",
      "Epoch 660/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3834 - val_loss: 0.3083\n",
      "Epoch 661/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3820 - val_loss: 0.3102\n",
      "Epoch 662/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3875 - val_loss: 0.3086\n",
      "Epoch 663/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3804 - val_loss: 0.3092\n",
      "Epoch 664/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3850 - val_loss: 0.3086\n",
      "Epoch 665/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3816 - val_loss: 0.3085\n",
      "Epoch 666/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3807 - val_loss: 0.3089\n",
      "Epoch 667/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3817 - val_loss: 0.3087\n",
      "Epoch 668/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3811 - val_loss: 0.3096\n",
      "Epoch 669/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3817 - val_loss: 0.3085\n",
      "Epoch 670/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3780 - val_loss: 0.3096\n",
      "Epoch 671/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3837 - val_loss: 0.3087\n",
      "Epoch 672/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3868 - val_loss: 0.3085\n",
      "Epoch 673/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3839 - val_loss: 0.3085\n",
      "Epoch 674/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3843 - val_loss: 0.3096\n",
      "Epoch 675/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3841 - val_loss: 0.3084\n",
      "Epoch 676/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3830 - val_loss: 0.3092\n",
      "Epoch 677/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3833 - val_loss: 0.3087\n",
      "Epoch 678/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3844 - val_loss: 0.3085\n",
      "Epoch 679/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3816 - val_loss: 0.3088\n",
      "Epoch 680/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3817 - val_loss: 0.3106\n",
      "Epoch 681/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3849 - val_loss: 0.3087\n",
      "Epoch 682/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3793 - val_loss: 0.3087\n",
      "Epoch 683/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3889 - val_loss: 0.3083\n",
      "Epoch 684/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3812 - val_loss: 0.3111\n",
      "Epoch 685/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3891 - val_loss: 0.3085\n",
      "Epoch 686/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3840 - val_loss: 0.3090\n",
      "Epoch 687/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3815 - val_loss: 0.3091\n",
      "Epoch 688/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3843 - val_loss: 0.3083\n",
      "Epoch 689/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3835 - val_loss: 0.3089\n",
      "Epoch 690/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3773 - val_loss: 0.3096\n",
      "Epoch 691/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3848 - val_loss: 0.3084\n",
      "Epoch 692/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3798 - val_loss: 0.3105\n",
      "Epoch 693/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3840 - val_loss: 0.3086\n",
      "Epoch 694/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3817 - val_loss: 0.3092\n",
      "Epoch 695/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3824 - val_loss: 0.3086\n",
      "Epoch 696/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3797 - val_loss: 0.3130\n",
      "Epoch 697/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3869 - val_loss: 0.3093\n",
      "Epoch 698/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3845 - val_loss: 0.3098\n",
      "Epoch 699/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3846 - val_loss: 0.3091\n",
      "Epoch 700/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3802 - val_loss: 0.3090\n",
      "Epoch 701/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3795 - val_loss: 0.3093\n",
      "Epoch 702/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3858 - val_loss: 0.3084\n",
      "Epoch 703/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3847 - val_loss: 0.3087\n",
      "Epoch 704/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3788 - val_loss: 0.3105\n",
      "Epoch 705/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3874 - val_loss: 0.3086\n",
      "Epoch 706/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3794 - val_loss: 0.3105\n",
      "Epoch 707/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3843 - val_loss: 0.3084\n",
      "Epoch 708/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3881 - val_loss: 0.3090\n",
      "Epoch 709/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3858 - val_loss: 0.3089\n",
      "Epoch 710/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3832 - val_loss: 0.3089\n",
      "Epoch 711/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3787 - val_loss: 0.3096\n",
      "Epoch 712/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3853 - val_loss: 0.3085\n",
      "Epoch 713/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3851 - val_loss: 0.3097\n",
      "Epoch 714/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3787 - val_loss: 0.3099\n",
      "Epoch 715/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3804 - val_loss: 0.3089\n",
      "Epoch 716/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3872 - val_loss: 0.3085\n",
      "Epoch 717/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3802 - val_loss: 0.3105\n",
      "Epoch 718/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3861 - val_loss: 0.3086\n",
      "Epoch 719/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3831 - val_loss: 0.3088\n",
      "Epoch 720/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3801 - val_loss: 0.3098\n",
      "Epoch 721/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3825 - val_loss: 0.3089\n",
      "Epoch 722/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3875 - val_loss: 0.3089\n",
      "Epoch 723/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3851 - val_loss: 0.3088\n",
      "Epoch 724/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3860 - val_loss: 0.3092\n",
      "Epoch 725/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3847 - val_loss: 0.3089\n",
      "Epoch 726/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3841 - val_loss: 0.3085\n",
      "Epoch 727/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3791 - val_loss: 0.3099\n",
      "Epoch 728/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3858 - val_loss: 0.3087\n",
      "Epoch 729/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3818 - val_loss: 0.3106\n",
      "Epoch 730/750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3824 - val_loss: 0.3091\n",
      "Epoch 731/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3800 - val_loss: 0.3091\n",
      "Epoch 732/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3857 - val_loss: 0.3088\n",
      "Epoch 733/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3828 - val_loss: 0.3095\n",
      "Epoch 734/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3831 - val_loss: 0.3088\n",
      "Epoch 735/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3787 - val_loss: 0.3108\n",
      "Epoch 736/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3780 - val_loss: 0.3100\n",
      "Epoch 737/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3817 - val_loss: 0.3089\n",
      "Epoch 738/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3890 - val_loss: 0.3094\n",
      "Epoch 739/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3784 - val_loss: 0.3124\n",
      "Epoch 740/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3848 - val_loss: 0.3087\n",
      "Epoch 741/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3847 - val_loss: 0.3088\n",
      "Epoch 742/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3833 - val_loss: 0.3096\n",
      "Epoch 743/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3811 - val_loss: 0.3103\n",
      "Epoch 744/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3786 - val_loss: 0.3087\n",
      "Epoch 745/750\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3808 - val_loss: 0.3090\n",
      "Epoch 746/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3853 - val_loss: 0.3097\n",
      "Epoch 747/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3855 - val_loss: 0.3090\n",
      "Epoch 748/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3816 - val_loss: 0.3087\n",
      "Epoch 749/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3794 - val_loss: 0.3098\n",
      "Epoch 750/750\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3804 - val_loss: 0.3092\n"
     ]
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(11, kernel_initializer = 'truncated_normal', use_bias = True, bias_initializer=\"zeros\", activation='relu',input_dim = 15))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(7, kernel_initializer = 'truncated_normal', use_bias = True, bias_initializer=\"zeros\", activation='relu'))\n",
    "\n",
    "# Adding the third hidden layer\n",
    "classifier.add(Dense(4, kernel_initializer = 'truncated_normal', use_bias = True, bias_initializer=\"zeros\", activation='relu'))\n",
    "\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(1, kernel_initializer = 'truncated_normal', use_bias = True, bias_initializer=\"zeros\", activation='relu'))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(loss=root_mean_squared_error, optimizer='Adamax')\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "model_history=classifier.fit(train_x.values, train_y.values,validation_split=0.15, batch_size = 500, epochs = 750)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DOJ Extended                   float64\n",
       "Duration to accept offer       float64\n",
       "Notice period                  float64\n",
       "Offered band                   float64\n",
       "Pecent hike expected in CTC    float64\n",
       "Percent hike offered in CTC    float64\n",
       "Percent difference CTC         float64\n",
       "Joining Bonus                  float64\n",
       "Candidate relocate actual      float64\n",
       "Gender                         float64\n",
       "Candidate Source               float64\n",
       "Rex in Yrs                     float64\n",
       "LOB                            float64\n",
       "Location                       float64\n",
       "Age                            float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Yogen\\Documents\\Data Analysis and Machine Learning\\Ishan Competition- Job Acceptance\\assets\n"
     ]
    }
   ],
   "source": [
    "classifier.save(r'C:\\Users\\Yogen\\Documents\\Data Analysis and Machine Learning\\Ishan Competition- Job Acceptance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.read_csv(r'C:\\Users\\Yogen\\Documents\\Data Analysis and Machine Learning\\Ishan Competition- Job Acceptance\\Testing-Modified.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input to the model we have trained\n",
    "test_x=test.iloc[:,2:17] #keeping only independent variables\n",
    "\n",
    "#changing data types to float64 to pass in the trained ANN\n",
    "for i in test_x.columns:\n",
    "    test_x[i]=test_x[i].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicted variable correct answers\n",
    "test_y=pd.DataFrame(test['Status'].astype('float64'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y=pd.DataFrame(classifier.predict(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.928697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.979742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.964359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.566227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.960216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075</th>\n",
       "      <td>1.024223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076</th>\n",
       "      <td>0.904335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077</th>\n",
       "      <td>0.880495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>0.871530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079</th>\n",
       "      <td>0.888475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1080 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "0     0.928697\n",
       "1     0.979742\n",
       "2     0.964359\n",
       "3     0.566227\n",
       "4     0.960216\n",
       "...        ...\n",
       "1075  1.024223\n",
       "1076  0.904335\n",
       "1077  0.880495\n",
       "1078  0.871530\n",
       "1079  0.888475\n",
       "\n",
       "[1080 rows x 1 columns]"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y.loc[predicted_y[0] > 1]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.928697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.979742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.964359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.960216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.897145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076</th>\n",
       "      <td>0.904335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077</th>\n",
       "      <td>0.880495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>0.871530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079</th>\n",
       "      <td>0.888475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>834 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "0     0.928697\n",
       "1     0.979742\n",
       "2     0.964359\n",
       "4     0.960216\n",
       "6     0.897145\n",
       "...        ...\n",
       "1075  1.000000\n",
       "1076  0.904335\n",
       "1077  0.880495\n",
       "1078  0.871530\n",
       "1079  0.888475\n",
       "\n",
       "[834 rows x 1 columns]"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_y.loc[predicted_y[0] >0.75]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding error in our predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_table=pd.DataFrame(test_y['Status']-predicted_y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_table['Squared Error']=error_table[0]*error_table[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148.43360026281562"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(error_table['Squared Error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission database predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission=pd.read_csv(r'C:\\Users\\Yogen\\Documents\\Data Analysis and Machine Learning\\Ishan Competition- Job Acceptance\\Test Data (Submission)-Modified.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SLNO</th>\n",
       "      <th>Candidate Ref</th>\n",
       "      <th>DOJ Extended</th>\n",
       "      <th>Duration to accept offer</th>\n",
       "      <th>Notice period</th>\n",
       "      <th>Offered band</th>\n",
       "      <th>Pecent hike expected in CTC</th>\n",
       "      <th>Percent hike offered in CTC</th>\n",
       "      <th>Percent difference CTC</th>\n",
       "      <th>Joining Bonus</th>\n",
       "      <th>Candidate relocate actual</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Candidate Source</th>\n",
       "      <th>Rex in Yrs</th>\n",
       "      <th>LOB</th>\n",
       "      <th>Location</th>\n",
       "      <th>Age</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2112635</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>50.00</td>\n",
       "      <td>320.00</td>\n",
       "      <td>180.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>2119124</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>31.58</td>\n",
       "      <td>31.58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>2154264</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>28.21</td>\n",
       "      <td>37.18</td>\n",
       "      <td>7.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>2158703</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>45.45</td>\n",
       "      <td>60.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>2172982</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>30.00</td>\n",
       "      <td>30.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2694</th>\n",
       "      <td>12291</td>\n",
       "      <td>3808142</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>71.43</td>\n",
       "      <td>42.86</td>\n",
       "      <td>-16.67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2695</th>\n",
       "      <td>12304</td>\n",
       "      <td>3821185</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>49.07</td>\n",
       "      <td>42.59</td>\n",
       "      <td>-4.35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2696</th>\n",
       "      <td>12327</td>\n",
       "      <td>3828206</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>150.00</td>\n",
       "      <td>150.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2697</th>\n",
       "      <td>12332</td>\n",
       "      <td>3835433</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>76.92</td>\n",
       "      <td>53.85</td>\n",
       "      <td>-13.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2698</th>\n",
       "      <td>12333</td>\n",
       "      <td>3836076</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>45.25</td>\n",
       "      <td>14.09</td>\n",
       "      <td>-21.45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2699 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SLNO  Candidate Ref  DOJ Extended  Duration to accept offer  \\\n",
       "0         2        2112635             0                        18   \n",
       "1         7        2119124             1                        37   \n",
       "2        14        2154264             0                         3   \n",
       "3        16        2158703             0                        44   \n",
       "4        20        2172982             0                         1   \n",
       "...     ...            ...           ...                       ...   \n",
       "2694  12291        3808142             0                         1   \n",
       "2695  12304        3821185             0                         2   \n",
       "2696  12327        3828206             1                         2   \n",
       "2697  12332        3835433             0                         0   \n",
       "2698  12333        3836076             0                         2   \n",
       "\n",
       "      Notice period  Offered band  Pecent hike expected in CTC  \\\n",
       "0                 1             2                        50.00   \n",
       "1                 1             2                        31.58   \n",
       "2                 0             2                        28.21   \n",
       "3                 4             2                        45.45   \n",
       "4                 0             2                        30.00   \n",
       "...             ...           ...                          ...   \n",
       "2694              1             1                        71.43   \n",
       "2695              0             1                        49.07   \n",
       "2696              0             1                       150.00   \n",
       "2697              1             1                        76.92   \n",
       "2698              0             1                        45.25   \n",
       "\n",
       "      Percent hike offered in CTC  Percent difference CTC  Joining Bonus  \\\n",
       "0                          320.00                  180.00              0   \n",
       "1                           31.58                    0.00              0   \n",
       "2                           37.18                    7.00              0   \n",
       "3                           60.00                   10.00              0   \n",
       "4                           30.00                    0.00              0   \n",
       "...                           ...                     ...            ...   \n",
       "2694                        42.86                  -16.67              0   \n",
       "2695                        42.59                   -4.35              0   \n",
       "2696                       150.00                    0.00              0   \n",
       "2697                        53.85                  -13.04              0   \n",
       "2698                        14.09                  -21.45              0   \n",
       "\n",
       "      Candidate relocate actual  Gender  Candidate Source  Rex in Yrs  LOB  \\\n",
       "0                             0       0                 0           8    0   \n",
       "1                             0       0                 0           7    0   \n",
       "2                             0       0                 0           7    0   \n",
       "3                             0       0                 1           8    0   \n",
       "4                             0       0                 1           6    0   \n",
       "...                         ...     ...               ...         ...  ...   \n",
       "2694                          0       0                 1           2    0   \n",
       "2695                          0       0                 2           5    1   \n",
       "2696                          0       1                 1           3    2   \n",
       "2697                          0       0                 1           4    0   \n",
       "2698                          0       1                 0           1    0   \n",
       "\n",
       "      Location  Age  Status  \n",
       "0            1   34     NaN  \n",
       "1            0   32     NaN  \n",
       "2            1   34     NaN  \n",
       "3            0   34     NaN  \n",
       "4            0   34     NaN  \n",
       "...        ...  ...     ...  \n",
       "2694         0   34     NaN  \n",
       "2695         0   34     NaN  \n",
       "2696         1   34     NaN  \n",
       "2697         0   34     NaN  \n",
       "2698         1   34     NaN  \n",
       "\n",
       "[2699 rows x 18 columns]"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input to the model we have trained\n",
    "submission_x=submission.iloc[:,2:17] #keeping only independent variables\n",
    "\n",
    "#changing data types to float64 to pass in the trained ANN\n",
    "for i in submission_x.columns:\n",
    "    submission_x[i]=submission_x[i].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicted variable correct answers\n",
    "submission_y=pd.DataFrame(classifier.predict(submission_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_y.loc[submission_y[0] > 1]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['Status']=submission_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(r'C:\\Users\\Yogen\\Documents\\Data Analysis and Machine Learning\\Ishan Competition- Job Acceptance\\WITH PREDICTIONS-Test Data (Submission)-Modified.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
